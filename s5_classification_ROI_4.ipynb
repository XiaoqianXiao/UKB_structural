{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T17:07:57.625962Z",
     "start_time": "2024-12-16T17:07:57.624262Z"
    }
   },
   "cell_type": "code",
   "source": "del list",
   "id": "e8b449e9734fbb45",
   "outputs": [],
   "execution_count": 461
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T00:17:57.206979Z",
     "start_time": "2024-12-18T00:17:57.202081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tian 1:10, 17:26\n",
    "subcortical_index = list(range(0,10)) + list(range(16,26))\n",
    "subcortical_name = ['aHIP-rh', 'pHIP-rh', 'lAMY-rh', 'mAMY-rh', 'THA-DP-rh', 'THA-VP-rh', 'THA-VA-rh', 'THA-DA-rh', 'NAc-shell-rh', 'NAc-core-rh', 'aHIP-lh', 'pHIP-lh', 'lAMY-lh', 'mAMY-lh', 'THA-DP-lh', 'THA-VP-lh', 'THA-VA-lh', 'THA-DA-lh', 'NAc-shell-lh', 'NAc-core-lh']\n",
    "# Schaefer: \n",
    "# lh-mPFC: 199:205\n",
    "# rh-mPFC: 464:470\n",
    "# lh-Ins: 67, 108:111, 126:128\n",
    "# rh-Ins: 319, 361:364, 383:386\n",
    "## ACC: 390\n",
    "# Glasser\n",
    "cortical_roi = ['lh_dlPFC', 'rh_dlPFC', 'lh_mPFC', 'rh_mPFC', 'lh_PCC', 'rh_PCC', 'lh_Ins', 'rh_Ins']\n",
    "lh_dlPFC_index = [205, 246, 247, 249, 250, 252, 262, 263, 264, 265, 266, 276, 277]\n",
    "rh_dlPFC_index = [25, 66, 67, 69, 70, 72, 82, 83, 84, 85, 86, 96, 97]\n",
    "lh_mPFC_index = [236, 237, 238, 239, 240, 241, 242, 243, 244, 248, 267, 343, 344, 345, 358, 359]\n",
    "rh_mPFC_index = [56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 87, 163, 164, 165, 178, 179]\n",
    "lh_PCC_index = [193, 194, 206, 209, 210, 211, 212, 213, 214, 300, 321, 340, 341]\n",
    "rh_PCC_index = [13, 14, 26, 29, 30, 31, 32, 33, 34, 120, 141, 160, 161]\n",
    "lh_Ins_index = [285, 287, 288, 289, 290, 291, 293, 294, 346, 347, 348, 357]\n",
    "rh_Ins_index = [105, 107, 108, 109, 110, 111, 113, 114, 166, 167, 168, 177]\n",
    "dic_cortical_roi = {\n",
    "    'lh_dlPFC': lh_dlPFC_index,\n",
    "    'rh_dlPFC': rh_dlPFC_index,\n",
    "    'lh_mPFC': lh_mPFC_index,\n",
    "    'rh_mPFC': rh_mPFC_index,\n",
    "    'lh_PCC': lh_PCC_index,\n",
    "    'rh_PCC': rh_PCC_index,\n",
    "    'lh_Ins': lh_Ins_index,\n",
    "    'rh_Ins': rh_Ins_index\n",
    "}"
   ],
   "id": "5fc54c0c71675a67",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T00:19:28.226813Z",
     "start_time": "2024-12-18T00:19:28.224885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "roi_list = cortical_roi + subcortical_name\n",
    "print(roi_list)\n",
    "connectivity_labels = [\n",
    "    f\"{roi1}--{roi2}\" for roi1, roi2 in itertools.combinations(roi_list, 2)\n",
    "]\n",
    "\n",
    "# Display the first 10 connectivity labels as a sample\n",
    "print(connectivity_labels[:10])"
   ],
   "id": "6963a5d50a88da61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lh_dlPFC', 'rh_dlPFC', 'lh_mPFC', 'rh_mPFC', 'lh_PCC', 'rh_PCC', 'lh_Ins', 'rh_Ins', 'aHIP-rh', 'pHIP-rh', 'lAMY-rh', 'mAMY-rh', 'THA-DP-rh', 'THA-VP-rh', 'THA-VA-rh', 'THA-DA-rh', 'NAc-shell-rh', 'NAc-core-rh', 'aHIP-lh', 'pHIP-lh', 'lAMY-lh', 'mAMY-lh', 'THA-DP-lh', 'THA-VP-lh', 'THA-VA-lh', 'THA-DA-lh', 'NAc-shell-lh', 'NAc-core-lh']\n",
      "['lh_dlPFC--rh_dlPFC', 'lh_dlPFC--lh_mPFC', 'lh_dlPFC--rh_mPFC', 'lh_dlPFC--lh_PCC', 'lh_dlPFC--rh_PCC', 'lh_dlPFC--lh_Ins', 'lh_dlPFC--rh_Ins', 'lh_dlPFC--aHIP-rh', 'lh_dlPFC--pHIP-rh', 'lh_dlPFC--lAMY-rh']\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T00:19:45.796341Z",
     "start_time": "2024-12-18T00:19:45.792500Z"
    }
   },
   "cell_type": "code",
   "source": "len(connectivity_labels)",
   "id": "5b520db1a6ed43e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T06:03:35.795719Z",
     "start_time": "2024-12-17T06:03:34.634777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "\n",
    "# === Step 1: Define Functions === #\n",
    "\n",
    "def load_dataset(base_dir, data_set):\n",
    "    \"\"\"\n",
    "    Load dataset-specific files.\n",
    "    \"\"\"\n",
    "    fMRIinfo_file_path = os.path.join(base_dir, f\"{data_set}_data_set.csv\")\n",
    "    participant_file_path = os.path.join(base_dir, \"participants_fMRI.csv\")\n",
    "    return pd.read_csv(fMRIinfo_file_path), pd.read_csv(participant_file_path)\n",
    "\n",
    "\n",
    "def load_subject_timeseries(subject_ID, session_ID, derivatives_dir, dic_cortical_roi, subcortical_index):\n",
    "    \"\"\"\n",
    "    Load cortical and subcortical timeseries data for a subject.\n",
    "    \"\"\"\n",
    "    cortical_file_name = f\"sub-{subject_ID}_ses-{session_ID}_task-rest_space-Glasser.csv.gz\"\n",
    "    cortical_file_path = os.path.join(derivatives_dir, \"timeseries\", cortical_file_name)\n",
    "\n",
    "    subcortical_file_name = f\"sub-{subject_ID}_ses-{session_ID}_task-rest_space-Tian_Subcortex_S2_3T.csv.gz\"\n",
    "    subcortical_file_path = os.path.join(derivatives_dir, \"timeseries\", subcortical_file_name)\n",
    "\n",
    "    if not (os.path.exists(cortical_file_path) and os.path.exists(subcortical_file_path)):\n",
    "        print(f\"Missing files for subject {subject_ID}, session {session_ID}.\")\n",
    "        return None\n",
    "\n",
    "    # Load and process cortical timeseries\n",
    "    df_cortical_all = pd.read_csv(cortical_file_path, compression=\"gzip\", index_col=0, header=0)\n",
    "    df_cortical_roi = pd.DataFrame({\n",
    "        roi: df_cortical_all.iloc[dic_cortical_roi[roi]].mean(axis=0)\n",
    "        for roi in dic_cortical_roi.keys()\n",
    "    })\n",
    "\n",
    "    # Load and process subcortical timeseries\n",
    "    df_subcortical_all = pd.read_csv(subcortical_file_path, compression=\"gzip\", index_col=0, header=0)\n",
    "    df_subcortical_roi = df_subcortical_all.iloc[subcortical_index]\n",
    "\n",
    "    # Combine cortical and subcortical ROIs\n",
    "    return pd.concat([df_cortical_roi, df_subcortical_roi.transpose()], axis=1)\n",
    "\n",
    "\n",
    "def clean_data(data):\n",
    "    \"\"\"\n",
    "    Handle missing values and remove constant features from time series data.\n",
    "    \"\"\"\n",
    "    # Fill NaNs with column-wise means\n",
    "    data_filled = np.copy(data)\n",
    "    for j in range(data.shape[1]):\n",
    "        if np.isnan(data[:, j]).any():\n",
    "            data_filled[:, j] = np.nan_to_num(data[:, j], nan=np.nanmean(data[:, j]))\n",
    "\n",
    "    # Remove constant features\n",
    "    non_constant_features = data_filled[:, data_filled.std(axis=0) != 0]\n",
    "    return non_constant_features\n",
    "\n",
    "\n",
    "def compute_connectivity(data):\n",
    "    \"\"\"\n",
    "    Compute connectivity matrix for the given time series data.\n",
    "    \"\"\"\n",
    "    correlation_measure = ConnectivityMeasure(kind=\"correlation\")\n",
    "    return correlation_measure.fit_transform([data])[0]\n",
    "\n",
    "\n",
    "def extract_upper_triangle(matrix):\n",
    "    \"\"\"\n",
    "    Extract the upper triangle values (excluding diagonal) from a connectivity matrix.\n",
    "    \"\"\"\n",
    "    upper_tri_indices = np.triu_indices(matrix.shape[0], k=1)\n",
    "    return matrix[upper_tri_indices]\n",
    "\n",
    "\n",
    "# === Step 2: Define the Pipeline === #\n",
    "\n",
    "def process_fMRI_subject(subject_ID, session_ID, derivatives_dir, dic_cortical_roi, subcortical_index):\n",
    "    \"\"\"\n",
    "    Full pipeline for processing a single subject's fMRI data.\n",
    "    \"\"\"\n",
    "    # Load subject timeseries\n",
    "    df_roi = load_subject_timeseries(subject_ID, session_ID, derivatives_dir, dic_cortical_roi, subcortical_index)\n",
    "    if df_roi is None:\n",
    "        return None, None\n",
    "\n",
    "    # Clean data\n",
    "    #cleaned_data = clean_data(df_roi.values)\n",
    "\n",
    "    # Standardize data\n",
    "    standardized_data = StandardScaler().fit_transform(df_roi.values)\n",
    "\n",
    "    # Compute connectivity matrix\n",
    "    connectivity_matrix = compute_connectivity(standardized_data)\n",
    "\n",
    "    # Extract upper triangle\n",
    "    upper_triangle = extract_upper_triangle(connectivity_matrix)\n",
    "\n",
    "    return upper_triangle, subject_ID\n",
    "\n",
    "\n",
    "def process_fMRI_data(data_set, user_dir, project_name, session_ID, dic_cortical_roi, subcortical_index):\n",
    "    \"\"\"\n",
    "    Full pipeline for processing fMRI data for all subjects.\n",
    "    \"\"\"\n",
    "    # Set paths\n",
    "    base_dir = os.path.join(user_dir, project_name, \"data\")\n",
    "    derivatives_dir = os.path.join(base_dir, \"derivatives\")\n",
    "\n",
    "    # Load dataset\n",
    "    df_fMRIinfo, df_participants = load_dataset(base_dir, data_set)\n",
    "    subject_IDs = df_fMRIinfo[\"eid\"].unique()\n",
    "\n",
    "    # Initialize lists for data\n",
    "    connectivity_data = []\n",
    "    subject_ids_cleaned = []\n",
    "\n",
    "    # Process each subject individually\n",
    "    for subject_ID in subject_IDs:\n",
    "        upper_triangle, cleaned_subject_ID = process_fMRI_subject(\n",
    "            subject_ID, session_ID, derivatives_dir, dic_cortical_roi, subcortical_index\n",
    "        )\n",
    "        if upper_triangle is not None:\n",
    "            connectivity_data.append(upper_triangle)\n",
    "            subject_ids_cleaned.append(cleaned_subject_ID)\n",
    "\n",
    "    # Filter participants based on available data\n",
    "    df_filtered = df_participants.loc[df_participants[\"eid\"].isin(subject_ids_cleaned)]\n",
    "\n",
    "    return np.array(connectivity_data), df_filtered\n"
   ],
   "id": "c2c46bdad1394cae",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T22:46:47.377149Z",
     "start_time": "2024-12-17T22:46:47.361634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#codes for modeling\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Perform stratified 10-Fold Cross-Validation\n",
    "stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Ensure binary target\n",
    "def ensure_binary_target(y):\n",
    "    unique_values = np.unique(y)\n",
    "    if len(unique_values) > 2:\n",
    "        raise ValueError(\"Target variable contains more than two classes. Please preprocess the data.\")\n",
    "    if unique_values.dtype == bool:\n",
    "        return y.astype(int)\n",
    "    elif set(unique_values) == {0, 1} or set(unique_values) == {1, 0}:\n",
    "        return y\n",
    "    else:\n",
    "        raise ValueError(\"Target variable is not binary. Please preprocess the data.\")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split data into training and testing sets while preserving class distribution\n",
    "def split_data(X, y, N_random_state, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Split the data into training and testing sets while preserving class ratios.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Features.\n",
    "    - y: Target labels.\n",
    "    - test_size: Proportion of the dataset to include in the test split.\n",
    "    - random_state: Random state for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "    - X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=N_random_state, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "# Model selection using cross-validation\n",
    "def model_selection(X_train, y_train):\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(),  # Provides coefficients (coef_)\n",
    "        \"Ridge Classifier\": LogisticRegression(penalty='l2', solver='liblinear'),  # coef_\n",
    "        \"Lasso (L1)\": LogisticRegression(penalty='l1', solver='liblinear'),  # coef_\n",
    "        \"LDA\": LinearDiscriminantAnalysis(),  # Provides coefficients (coef_)\n",
    "        \"Perceptron\": Perceptron(),  # Provides coefficients (coef_)\n",
    "        \"SVM (Linear)\": SVC(kernel='linear'),  # Provides coefficients (coef_) when kernel='linear'\n",
    "        \"Random Forest\": RandomForestClassifier(),  # Provides feature_importances_\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "    best_score = -np.inf\n",
    "    best_name = \"\"\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        cv_score = cross_val_score(model, X_train, y_train, cv=stratified_kfold, scoring='accuracy').mean()\n",
    "        print(f\"Model: {model_name}, CV Score: {cv_score:.4f}\")\n",
    "\n",
    "        if cv_score > best_score:\n",
    "            best_score = cv_score\n",
    "            best_model = model\n",
    "            best_name = model_name\n",
    "\n",
    "    print(f\"Best Model: {best_name} with CV score: {best_score:.4f}\")\n",
    "    return best_model, best_name\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "\n",
    "def feature_selection_with_rfe(X_train, y_train, n_features, best_model):\n",
    "    \"\"\"\n",
    "    Perform feature selection using RFE, with fallback to univariate selection for models without coefficients.\n",
    "    \"\"\"\n",
    "    if hasattr(best_model, \"coef_\") or hasattr(best_model, \"feature_importances_\"):\n",
    "        # Use RFE for models with coefficients or feature importances\n",
    "        rfe = RFE(estimator=best_model, n_features_to_select=n_features, step=1)\n",
    "        rfe.fit(X_train, y_train)\n",
    "\n",
    "        selected_features = rfe.support_\n",
    "        if np.sum(selected_features) == 0:\n",
    "            print(\"No features selected using RFE. Using all features as fallback.\")\n",
    "            selected_features = np.ones(X_train.shape[1], dtype=bool)\n",
    "\n",
    "    else:\n",
    "        # Fallback to univariate feature selection\n",
    "        print(\"Model lacks coefficients/feature importance; using univariate feature selection.\")\n",
    "        \n",
    "        # Use SelectKBest with F-statistic (or mutual information if preferred)\n",
    "        selector = SelectKBest(score_func=f_classif, k=n_features)\n",
    "        selector.fit(X_train, y_train)\n",
    "\n",
    "        selected_features = selector.get_support()\n",
    "        if np.sum(selected_features) == 0:\n",
    "            print(\"No features selected using univariate method. Using all features as fallback.\")\n",
    "            selected_features = np.ones(X_train.shape[1], dtype=bool)\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_classif\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "def feature_selection_with_rfe_cv(X_train, y_train, best_model, scoring_metric='accuracy'):\n",
    "    \"\"\"\n",
    "    Perform feature selection using RFE or univariate selection, optimizing the number of features automatically\n",
    "    using cross-validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def evaluate_features(model, X, y, num_features):\n",
    "        \"\"\"\n",
    "        Helper function to evaluate the model's performance with the given number of features using cross-validation.\n",
    "        \"\"\"\n",
    "        if hasattr(model, \"coef_\") or hasattr(model, \"feature_importances_\"):\n",
    "            # Perform RFE with the given number of features\n",
    "            rfe = RFE(estimator=model, n_features_to_select=num_features, step=1)\n",
    "            X_selected = rfe.fit_transform(X, y)\n",
    "        else:\n",
    "            # Use univariate feature selection as a fallback\n",
    "            selector = SelectKBest(score_func=f_classif, k=num_features)\n",
    "            X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "        # Evaluate model performance using cross-validation\n",
    "        scores = cross_val_score(model, X_selected, y, cv=stratified_kfold, scoring=scoring_metric)\n",
    "        return scores.mean()\n",
    "\n",
    "    # Iterate over a range of features to find the optimal number of features\n",
    "    best_score = -np.inf\n",
    "    optimal_num_features = 0\n",
    "    for num_features in range(1, X_train.shape[1] + 1):\n",
    "        score = evaluate_features(best_model, X_train, y_train, num_features)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            optimal_num_features = num_features\n",
    "\n",
    "    print(f\"Optimal number of features: {optimal_num_features} with cross-validated score: {best_score:.4f}\")\n",
    "\n",
    "    # Perform final RFE or univariate selection with the optimal number of features\n",
    "    if hasattr(best_model, \"coef_\") or hasattr(best_model, \"feature_importances_\"):\n",
    "        rfe = RFE(estimator=best_model, n_features_to_select=optimal_num_features, step=1)\n",
    "        rfe.fit(X_train, y_train)\n",
    "        selected_features = rfe.support_\n",
    "    else:\n",
    "        selector = SelectKBest(score_func=f_classif, k=optimal_num_features)\n",
    "        selector.fit(X_train, y_train)\n",
    "        selected_features = selector.get_support()\n",
    "\n",
    "    return selected_features, optimal_num_features\n",
    "\n",
    "\n",
    "# Two-step grid search for hyperparameter optimization\n",
    "def tune_model_hyperparameters(model, model_name, X_train, y_train):\n",
    "    refined_grid = {}  # Initialize with a default value to avoid \"unbound variable\" error\n",
    "\n",
    "    if model_name == \"Logistic Regression\":\n",
    "        broad_param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    elif model_name == \"Ridge Classifier\":\n",
    "        broad_param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    elif model_name == \"Lasso (L1)\" or model_name == \"ElasticNet (L1+L2)\":\n",
    "        broad_param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    elif model_name == \"SVM (Linear)\":\n",
    "        broad_param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    elif model_name == \"Random Forest\":\n",
    "        broad_param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30]}\n",
    "    elif model_name == \"Perceptron\":\n",
    "        broad_param_grid = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1]}\n",
    "    elif model_name == \"LDA\":\n",
    "        broad_param_grid = {'shrinkage': [None, 'auto'], 'solver': ['svd', 'lsqr', 'eigen']}\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} does not have a defined parameter grid.\")\n",
    "\n",
    "    # Broad Grid Search\n",
    "    broad_search = GridSearchCV(model, broad_param_grid, cv=stratified_kfold, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    broad_search.fit(X_train, y_train)\n",
    "    best_params_broad = broad_search.best_params_\n",
    "\n",
    "    # Define refined grid based on broad search results\n",
    "    if model_name in [\"Logistic Regression\", \"Lasso (L1)\", \"ElasticNet (L1+L2)\", \"SVM (Linear)\"]:\n",
    "        refined_grid = {'C': np.linspace(best_params_broad['C'] * 0.1, best_params_broad['C'] * 10, 5)}\n",
    "    elif model_name == \"Random Forest\":\n",
    "        refined_grid = {\n",
    "            'n_estimators': [max(10, best_params_broad['n_estimators'] - 50), best_params_broad['n_estimators'], best_params_broad['n_estimators'] + 50],\n",
    "            'max_depth': [None] if not best_params_broad['max_depth'] else [\n",
    "                max(1, best_params_broad['max_depth'] - 5), best_params_broad['max_depth'], best_params_broad['max_depth'] + 5]\n",
    "        }\n",
    "    elif model_name == \"Perceptron\":\n",
    "        refined_grid = {'alpha': np.linspace(best_params_broad['alpha'] * 0.1, best_params_broad['alpha'] * 10, 5)}\n",
    "    elif model_name == \"LDA\":\n",
    "        refined_grid = {'shrinkage': [best_params_broad['shrinkage']], 'solver': [best_params_broad['solver']]}\n",
    "\n",
    "    # Narrow Grid Search\n",
    "    narrow_search = GridSearchCV(model, refined_grid, cv=stratified_kfold, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    narrow_search.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Best Parameters (Broad Search): {best_params_broad}\")\n",
    "    print(f\"Best Parameters (Narrow Search): {narrow_search.best_params_}\")\n",
    "\n",
    "    best_model = narrow_search.best_estimator_\n",
    "    return best_model\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Train and evaluate final model\n",
    "def train_and_evaluate_final_model(X_train, y_train, X_test, y_test, model):\n",
    "    \"\"\"\n",
    "    Train and evaluate the final model. Reports accuracy and AUC.\n",
    "    Parameters:\n",
    "    - X_train: Features for training.\n",
    "    - y_train: Labels for training.\n",
    "    - X_test: Features for testing.\n",
    "    - y_test: Labels for testing.\n",
    "    - model: Machine learning model (must support `fit` and `predict_proba`).\n",
    "\n",
    "    Returns:\n",
    "    - model: Trained model.\n",
    "    - test_accuracy: Accuracy on the test set.\n",
    "    - test_auc: AUC score on the test set.\n",
    "    \"\"\"\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    \n",
    "    # Predict probabilities for AUC computation\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "        test_auc = roc_auc_score(y_test, y_proba)\n",
    "        print(f\"Test Set AUC (Final Model): {test_auc:.4f}\")\n",
    "    else:\n",
    "        print(\"Model does not support probability predictions; skipping AUC computation.\")\n",
    "        test_auc = None\n",
    "\n",
    "    print(f\"Test Set Accuracy (Final Model): {test_accuracy:.4f}\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    return model, test_accuracy, test_auc\n",
    "\n",
    "\n",
    "\n",
    "# Cosine similarity between two models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_model_similarity(model1, model2):\n",
    "    \"\"\"\n",
    "    Calculate the similarity between two models using cosine similarity or feature importances.\n",
    "\n",
    "    Parameters:\n",
    "    - model1: First trained model\n",
    "    - model2: Second trained model\n",
    "\n",
    "    Returns:\n",
    "    - similarity: Cosine similarity score between the two models' coefficients or importances.\n",
    "    \"\"\"\n",
    "    # Extract the weights (coefficients) or feature importances\n",
    "    def get_model_vector(model):\n",
    "        if hasattr(model, 'coef_'):  # Linear models with coefficients\n",
    "            return model.coef_.flatten()\n",
    "        elif hasattr(model, 'feature_importances_'):  # Tree-based models\n",
    "            return model.feature_importances_\n",
    "        else:\n",
    "            raise ValueError(f\"Model of type {type(model)} does not have coefficients or feature importances.\")\n",
    "    \n",
    "    try:\n",
    "        # Get vectors for the two models\n",
    "        vector1 = get_model_vector(model1)\n",
    "        vector2 = get_model_vector(model2)\n",
    "\n",
    "        # Ensure vectors are of the same length\n",
    "        if len(vector1) != len(vector2):\n",
    "            raise ValueError(\"Model vectors have different lengths. Ensure the models were trained on the same features.\")\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        similarity = cosine_similarity([vector1], [vector2])\n",
    "        return similarity[0][0]  # Return the scalar similarity value\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in calculating similarity: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Full pipeline\n",
    "def pipeline1(X, y, n_features, N_random_state):\n",
    "    y = ensure_binary_target(y)\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, N_random_state)\n",
    "\n",
    "    best_model, best_name = model_selection(X_train, y_train)\n",
    "\n",
    "    selected_features = feature_selection_with_rfe(X_train, y_train, n_features, best_model)\n",
    "    X_train_selected = X_train[:, selected_features]\n",
    "    X_test_selected = X_test[:, selected_features]\n",
    "\n",
    "    tuned_model = tune_model_hyperparameters(best_model, best_name, X_train_selected, y_train)\n",
    "\n",
    "    final_model, test_accuracy, test_auc = train_and_evaluate_final_model(\n",
    "        X_train_selected, y_train, X_test_selected, y_test, tuned_model\n",
    "    )\n",
    "    return final_model, selected_features, test_accuracy\n",
    "\n",
    "def pipeline2(X, y, N_random_state):\n",
    "    y = ensure_binary_target(y)\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, N_random_state)\n",
    "\n",
    "    best_model, best_name = model_selection(X_train, y_train)\n",
    "\n",
    "    \n",
    "    selected_features, features_number = feature_selection_with_rfe_cv(X_train, y_train, best_model)\n",
    "    X_train_selected = X_train[:, selected_features]\n",
    "    X_test_selected = X_test[:, selected_features]\n",
    "\n",
    "    tuned_model = tune_model_hyperparameters(best_model, best_name, X_train_selected, y_train)\n",
    "\n",
    "    final_model, test_accuracy, test_auc = train_and_evaluate_final_model(\n",
    "        X_train_selected, y_train, X_test_selected, y_test, tuned_model\n",
    "    )\n",
    "    return final_model, selected_features, test_accuracy\n",
    "\n",
    "\n",
    "def compare_models_and_analyze_topography1(X_data_set1, y_data_set1, X_data_set2, y_data_set2, n_features, N_random_state):\n",
    "    print(\"Training data_set1 model...\")\n",
    "    final_model_data_set1, selected_features_data_set1, test_accuracy_data_set1 = pipeline1(X_data_set1, y_data_set1, n_features, N_random_state)\n",
    "    X_data_set1_selected = X_data_set1[:, selected_features_data_set1]\n",
    "    y_pred = final_model_data_set1.predict(X_data_set1_selected)\n",
    "    if test_accuracy_data_set1 < 0.63:\n",
    "        print(f\"Test accuracy ({test_accuracy_data_set1:.4f}) is below 0.63. Stopping pipeline.\")\n",
    "        return None, test_accuracy_data_set1, None, 0, None, 0  # Early exit with placeholder return values\n",
    "    \n",
    "    test_accuracy_all = final_model_data_set1.score(X_data_set1_selected, y_data_set1)\n",
    "    # if test_accuracy_all < 0.9:\n",
    "    #     print(f\"Test accuracy for all ({test_accuracy_all:.4f}) is below 0.9. Stopping pipeline.\")\n",
    "    #     return None, test_accuracy_data_set1, None, None, None, test_accuracy_all\n",
    "    print(\"Results for whole data_set1 model:\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set1, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_data_set1, y_pred))\n",
    "    \n",
    "    \n",
    "    print(\"\\nTraining data_set2 model...\")\n",
    "    final_model_data_set2, selected_features_data_set2, test_accuracy_data_set2 = pipeline1(X_data_set2, y_data_set2, n_features, N_random_state)\n",
    "    X_data_set2_selected = X_data_set2[:, selected_features_data_set2]\n",
    "    y_pred2 = final_model_data_set2.predict(X_data_set2_selected)\n",
    "    if test_accuracy_data_set2 < 0.63:\n",
    "        print(f\"Test accuracy for all ({test_accuracy_all:.4f}) is below 0.9. Stopping pipeline.\")\n",
    "        return None, test_accuracy_data_set1, None, 0, None, test_accuracy_all\n",
    "    print(\"Results for whole data_set2 model:\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set2, y_pred2))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_data_set2, y_pred2))\n",
    "    \n",
    "\n",
    "    print(\"\\nEvaluating data_set1 model on data_set2 dataset:\")\n",
    "    X_data_set2_selected = X_data_set2[:, selected_features_data_set1]\n",
    "    y_pred_data_set2 = final_model_data_set1.predict(X_data_set2_selected)\n",
    "    accuracy = accuracy_score(y_data_set2, y_pred_data_set2)\n",
    "    print(f\"Accuracy of data_set1 model on data_set2 data: {accuracy:.4f}\")\n",
    "    # Check if the model supports probability predictions for AUC computation\n",
    "    if hasattr(final_model_data_set1, \"predict_proba\"):\n",
    "        y_proba_data_set2 = final_model_data_set1.predict_proba(X_data_set2_selected)[:, 1]  # Probabilities for the positive class\n",
    "        auc = roc_auc_score(y_data_set2, y_proba_data_set2)\n",
    "        print(f\"Dataset 2 - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "    else:\n",
    "        print(f\"Dataset 2 - Accuracy: {accuracy:.4f}\")\n",
    "        auc = None  # AUC not computed due to lack of probability support\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set2, y_pred_data_set2))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_data_set2, y_pred_data_set2))\n",
    "\n",
    "    print(\"\\nCalculating cosine similarity between data_set1 and data_set2 model weights:\")\n",
    "    try:\n",
    "        similarity = calculate_model_similarity(final_model_data_set1, final_model_data_set2)\n",
    "        print(f\"Cosine similarity between data_set1 and data_set2 model weights: {similarity:.4f}\")\n",
    "    except ValueError as e:\n",
    "        similarity = \"N/A (Model type not compatible for cosine similarity)\"\n",
    "        print(f\"Cosine similarity between data_set1 and data_set2 model weights: {similarity}\")\n",
    "    return similarity, test_accuracy_data_set1, final_model_data_set1, test_accuracy_data_set2, final_model_data_set2, test_accuracy_all\n",
    "\n",
    "\n",
    "\n",
    "def compare_models_and_analyze_topography2(X_data_set1, y_data_set1, X_data_set2, y_data_set2, N_random_state):\n",
    "    print(\"Training data_set1 model...\")\n",
    "    final_model_data_set1, selected_features_data_set1, test_accuracy_data_set1 = pipeline2(X_data_set1, y_data_set1, N_random_state)\n",
    "    # X_data_set1_selected = X_data_set1[:, selected_features_data_set1]\n",
    "    # y_pred = final_model_data_set1.predict(X_data_set1_selected)\n",
    "    # print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set1, y_pred))\n",
    "    # print(\"Classification Report:\\n\", classification_report(y_data_set1, y_pred))\n",
    "    \n",
    "    print(\"\\nTraining data_set2 model...\")\n",
    "    final_model_data_set2, selected_features_data_set2, test_accuracy_data_set2 = pipeline2(X_data_set2, y_data_set2, N_random_state)\n",
    "    # X_data_set2_selected = X_data_set2[:, selected_features_data_set2]\n",
    "    # y_pred2 = final_model_data_set2.predict(X_data_set2_selected)\n",
    "    # print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set2, y_pred2))\n",
    "    # print(\"Classification Report:\\n\", classification_report(y_data_set2, y_pred2))\n",
    "    \n",
    "\n",
    "    print(\"\\nEvaluating data_set1 model on data_set2 dataset:\")\n",
    "    X_data_set2_selected = X_data_set2[:, selected_features_data_set1]\n",
    "    y_pred_data_set2 = final_model_data_set1.predict(X_data_set2_selected)\n",
    "    accuracy = accuracy_score(y_data_set2, y_pred_data_set2)\n",
    "    print(f\"Accuracy of data_set1 model on data_set2 data: {accuracy:.4f}\")\n",
    "    # Check if the model supports probability predictions for AUC computation\n",
    "    if hasattr(final_model_data_set1, \"predict_proba\"):\n",
    "        y_proba_data_set2 = final_model_data_set1.predict_proba(X_data_set2_selected)[:, 1]  # Probabilities for the positive class\n",
    "        auc = roc_auc_score(y_data_set2, y_proba_data_set2)\n",
    "        print(f\"Dataset 2 - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "    else:\n",
    "        print(f\"Dataset 2 - Accuracy: {accuracy:.4f}\")\n",
    "        auc = None  # AUC not computed due to lack of probability support\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set2, y_pred_data_set2))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_data_set2, y_pred_data_set2))\n",
    "\n",
    "    print(\"\\nCalculating cosine similarity between data_set1 and data_set2 model weights:\")\n",
    "    try:\n",
    "        similarity = calculate_model_similarity(final_model_data_set1, final_model_data_set2)\n",
    "        print(f\"Cosine similarity between data_set1 and data_set2 model weights: {similarity:.4f}\")\n",
    "    except ValueError as e:\n",
    "        similarity = \"N/A (Model type not compatible for cosine similarity)\"\n",
    "        print(f\"Cosine similarity between data_set1 and data_set2 model weights: {similarity}\")\n",
    "    return similarity, test_accuracy_data_set1"
   ],
   "id": "53f841406272c9d6",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T06:03:37.934616Z",
     "start_time": "2024-12-17T06:03:37.932681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define user inputs\n",
    "user_dir = \"/Users/xiaoqianxiao\"\n",
    "project_name = \"UKB\"\n",
    "session_ID = 2  # Specify session"
   ],
   "id": "d5f513afe68162b6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T06:03:44.874434Z",
     "start_time": "2024-12-17T06:03:39.200076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run the pipeline\n",
    "data_set = \"past_anxiety\"  # Dataset identifier\n",
    "X_pad, df_PAD = process_fMRI_data(data_set, user_dir, project_name, session_ID, dic_cortical_roi, subcortical_index)\n",
    "y_pad = df_PAD[\"hospital_not_now\"]\n",
    "y_pad_GAD7 = df_PAD[\"GAD7_score\"]\n",
    "\n",
    "data_set = \"current_anxiety\"  # Dataset identifier\n",
    "X_cad, df_CAD = process_fMRI_data(data_set, user_dir, project_name, session_ID, dic_cortical_roi, subcortical_index)\n",
    "y_cad = df_CAD[\"hospital_current_anxiety\"]\n",
    "y_cad_GAD7 = df_CAD[\"GAD7_score\"]"
   ],
   "id": "2fdce368bac9cc64",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Run the pipeline\u001B[39;00m\n\u001B[1;32m      2\u001B[0m data_set \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpast_anxiety\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# Dataset identifier\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m X_pad, df_PAD \u001B[38;5;241m=\u001B[39m \u001B[43mprocess_fMRI_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muser_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mproject_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msession_ID\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdic_cortical_roi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubcortical_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m y_pad \u001B[38;5;241m=\u001B[39m df_PAD[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhospital_not_now\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m      5\u001B[0m y_pad_GAD7 \u001B[38;5;241m=\u001B[39m df_PAD[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGAD7_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "Cell \u001B[0;32mIn[2], line 123\u001B[0m, in \u001B[0;36mprocess_fMRI_data\u001B[0;34m(data_set, user_dir, project_name, session_ID, dic_cortical_roi, subcortical_index)\u001B[0m\n\u001B[1;32m    121\u001B[0m \u001B[38;5;66;03m# Process each subject individually\u001B[39;00m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m subject_ID \u001B[38;5;129;01min\u001B[39;00m subject_IDs:\n\u001B[0;32m--> 123\u001B[0m     upper_triangle, cleaned_subject_ID \u001B[38;5;241m=\u001B[39m \u001B[43mprocess_fMRI_subject\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    124\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubject_ID\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msession_ID\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mderivatives_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdic_cortical_roi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubcortical_index\u001B[49m\n\u001B[1;32m    125\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    126\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m upper_triangle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    127\u001B[0m         connectivity_data\u001B[38;5;241m.\u001B[39mappend(upper_triangle)\n",
      "Cell \u001B[0;32mIn[2], line 86\u001B[0m, in \u001B[0;36mprocess_fMRI_subject\u001B[0;34m(subject_ID, session_ID, derivatives_dir, dic_cortical_roi, subcortical_index)\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;124;03mFull pipeline for processing a single subject's fMRI data.\u001B[39;00m\n\u001B[1;32m     84\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;66;03m# Load subject timeseries\u001B[39;00m\n\u001B[0;32m---> 86\u001B[0m df_roi \u001B[38;5;241m=\u001B[39m \u001B[43mload_subject_timeseries\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubject_ID\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msession_ID\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mderivatives_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdic_cortical_roi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubcortical_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m df_roi \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[2], line 34\u001B[0m, in \u001B[0;36mload_subject_timeseries\u001B[0;34m(subject_ID, session_ID, derivatives_dir, dic_cortical_roi, subcortical_index)\u001B[0m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# Load and process cortical timeseries\u001B[39;00m\n\u001B[0;32m---> 34\u001B[0m df_cortical_all \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcortical_file_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgzip\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m df_cortical_roi \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\n\u001B[1;32m     36\u001B[0m     roi: df_cortical_all\u001B[38;5;241m.\u001B[39miloc[dic_cortical_roi[roi]]\u001B[38;5;241m.\u001B[39mmean(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m roi \u001B[38;5;129;01min\u001B[39;00m dic_cortical_roi\u001B[38;5;241m.\u001B[39mkeys()\n\u001B[1;32m     38\u001B[0m })\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m# Load and process subcortical timeseries\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/ukbnexus-xiaoqian-PL9ZUpYW-py3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/ukbnexus-xiaoqian-PL9ZUpYW-py3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[0;32m--> 626\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/ukbnexus-xiaoqian-PL9ZUpYW-py3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m   1916\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[1;32m   1917\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1918\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[1;32m   1919\u001B[0m     (\n\u001B[1;32m   1920\u001B[0m         index,\n\u001B[1;32m   1921\u001B[0m         columns,\n\u001B[1;32m   1922\u001B[0m         col_dict,\n\u001B[0;32m-> 1923\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[1;32m   1924\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\n\u001B[1;32m   1925\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1926\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1927\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/ukbnexus-xiaoqian-PL9ZUpYW-py3.12/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlow_memory:\n\u001B[0;32m--> 234\u001B[0m         chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_low_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    235\u001B[0m         \u001B[38;5;66;03m# destructive to chunks\u001B[39;00m\n\u001B[1;32m    236\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T19:43:35.554260Z",
     "start_time": "2024-12-16T19:43:35.550760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'n(cad)/(cad_control): {sum(y_cad==True)}/{sum(y_cad==False)} = {((sum(y_cad==True))/(sum(y_cad==False))):.2f}')\n",
    "print(f'n(pad)/(pad_control): {sum(y_pad==True)}/{sum(y_pad==False)} = {((sum(y_pad==True))/(sum(y_pad==False))):.2f}')"
   ],
   "id": "48b294ec0ab1a0b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n(cad)/(cad_control): 118/106 = 1.11\n",
      "n(pad)/(pad_control): 511/478 = 1.07\n"
     ]
    }
   ],
   "execution_count": 498
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_features = 20\n",
    "compare_models_and_analyze_topography1(X_cad, y_cad, X_pad, y_pad, n_features)"
   ],
   "id": "e10c707687160969"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "similarity, test_accuracy_data_set1 = compare_models_and_analyze_topography2(X_cad, y_cad, X_pad, y_pad)",
   "id": "1e4ec938a36f74d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T06:06:20.516472Z",
     "start_time": "2024-12-17T06:03:57.038514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_set = \"ah\"  # Dataset identifier\n",
    "X_ah, df_ah = process_fMRI_data(data_set, user_dir, project_name, session_ID, dic_cortical_roi, subcortical_index)\n",
    "y_ah = df_ah[\"active_history\"]\n",
    "\n",
    "data_set = \"ih\"  # Dataset identifier\n",
    "X_ih, df_ih = process_fMRI_data(data_set, user_dir, project_name, session_ID, dic_cortical_roi, subcortical_index)\n",
    "y_ih = df_ih[\"inactive_history\"]\n",
    "\n",
    "data_set = \"a_noh\"  # Dataset identifier\n",
    "X_a_noh, df_a_noh = process_fMRI_data(data_set, user_dir, project_name, session_ID, dic_cortical_roi, subcortical_index)\n",
    "y_a_noh = df_a_noh[\"active_no_history\"]"
   ],
   "id": "f7b9d64c4a1a48d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files for subject 1529291, session 2.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T03:32:49.761645Z",
     "start_time": "2024-12-17T03:32:49.758687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'n(ah)/(ah_control): {sum(y_ah==True)}/{sum(y_ah==False)} = {((sum(y_ah==True))/(sum(y_ah==False))):.2f}')\n",
    "print(f'n(ih)/(ih_control): {sum(y_ih==True)}/{sum(y_ih==False)} = {((sum(y_ih==True))/(sum(y_ih==False))):.2f}')\n",
    "print(f'n(a_noh)/(a_noh_control): {sum(y_a_noh==True)}/{sum(y_a_noh==False)} = {((sum(y_a_noh==True))/(sum(y_a_noh==False))):.2f}')"
   ],
   "id": "e69030102072c264",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n(ah)/(ah_control): 367/337 = 1.09\n",
      "n(ih)/(ih_control): 874/819 = 1.07\n",
      "n(a_noh)/(a_noh_control): 250/233 = 1.07\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "a = 0\n",
    "b = 0\n",
    "N_random_state = 0\n",
    "while a < 0.65 or b < 0.65:\n",
    "    n_features = 10\n",
    "    similarity, test_accuracy_data_set1, final_model_data_set1, test_accuracy_data_set2, final_model_data_set2, test_accuracy_all = compare_models_and_analyze_topography1(X_ah, y_ah, X_ih, y_ih, n_features, N_random_state)\n",
    "    a = test_accuracy_data_set1\n",
    "    b = test_accuracy_data_set2\n",
    "    print(N_random_state)\n",
    "    N_random_state = N_random_state + 1"
   ],
   "id": "15847d6a9186262d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4a467674a4514be7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "compare_models_and_analyze_topography2(X_ah, y_ah, X_ih, y_ih)",
   "id": "a43b7204f4c6130d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "a = 0\n",
    "N_random_state = 0\n",
    "while a < 0.8:\n",
    "    n_features = 10\n",
    "    similarity, test_accuracy_data_set1, final_model_data_set1, final_model_data_set2 = compare_models_and_analyze_topography1(X_ah, y_ah, X_a_noh, y_a_noh, n_features,N_random_state)\n",
    "    a = test_accuracy_data_set1\n",
    "    print(N_random_state)\n",
    "    print(test_accuracy_data_set1)\n",
    "    N_random_state = N_random_state + 1"
   ],
   "id": "dfcc94fc54ca951c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "compare_models_and_analyze_topography2(X_ah, y_ah, X_a_noh, y_a_noh)",
   "id": "25410d07d9fd95e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T23:05:58.566996Z",
     "start_time": "2024-12-17T23:04:30.602218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_features = 10\n",
    "N_random_state = 0\n",
    "X_data_set1 = X_ah\n",
    "y_data_set1 = y_ah\n",
    "a = 0\n",
    "while a < 0.65: \n",
    "    final_model_data_set1, selected_features_data_set1, test_accuracy_data_set1 = pipeline1(X_data_set1, y_data_set1, n_features, N_random_state)\n",
    "    X_data_set1_selected = X_data_set1[:, selected_features_data_set1]\n",
    "    y_pred = final_model_data_set1.predict(X_data_set1_selected)\n",
    "    if test_accuracy_data_set1 > 0.63:\n",
    "        print(\"Results for whole data_set1 model:\")\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set1, y_pred))\n",
    "        print(\"Classification Report:\\n\", classification_report(y_data_set1, y_pred))\n",
    "    a = test_accuracy_data_set1\n",
    "    N_random_state = N_random_state + 1"
   ],
   "id": "f1df6de8aea866b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression, CV Score: 0.5488\n",
      "Model: Ridge Classifier, CV Score: 0.5488\n",
      "Model: Lasso (L1), CV Score: 0.5648\n",
      "Model: LDA, CV Score: 0.4707\n",
      "Model: Perceptron, CV Score: 0.5204\n",
      "Model: SVM (Linear), CV Score: 0.5470\n",
      "Model: Random Forest, CV Score: 0.5542\n",
      "Best Model: Lasso (L1) with CV score: 0.5648\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'C': 1}\n",
      "Best Parameters (Narrow Search): {'C': np.float64(2.575)}\n",
      "Test Set AUC (Final Model): 0.5508\n",
      "Test Set Accuracy (Final Model): 0.5674\n",
      "Confusion Matrix:\n",
      " [[32 35]\n",
      " [26 48]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.48      0.51        67\n",
      "           1       0.58      0.65      0.61        74\n",
      "\n",
      "    accuracy                           0.57       141\n",
      "   macro avg       0.57      0.56      0.56       141\n",
      "weighted avg       0.57      0.57      0.56       141\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.5204\n",
      "Model: Ridge Classifier, CV Score: 0.5222\n",
      "Model: Lasso (L1), CV Score: 0.5009\n",
      "Model: LDA, CV Score: 0.4533\n",
      "Model: Perceptron, CV Score: 0.5188\n",
      "Model: SVM (Linear), CV Score: 0.4903\n",
      "Model: Random Forest, CV Score: 0.4972\n",
      "Best Model: Ridge Classifier with CV score: 0.5222\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Best Parameters (Broad Search): {'C': 0.1}\n",
      "Best Parameters (Narrow Search): {}\n",
      "Test Set AUC (Final Model): 0.5212\n",
      "Test Set Accuracy (Final Model): 0.4610\n",
      "Confusion Matrix:\n",
      " [[23 44]\n",
      " [32 42]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.34      0.38        67\n",
      "           1       0.49      0.57      0.53        74\n",
      "\n",
      "    accuracy                           0.46       141\n",
      "   macro avg       0.45      0.46      0.45       141\n",
      "weighted avg       0.46      0.46      0.45       141\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.5241\n",
      "Model: Ridge Classifier, CV Score: 0.5276\n",
      "Model: Lasso (L1), CV Score: 0.5486\n",
      "Model: LDA, CV Score: 0.4636\n",
      "Model: Perceptron, CV Score: 0.4901\n",
      "Model: SVM (Linear), CV Score: 0.5204\n",
      "Model: Random Forest, CV Score: 0.5026\n",
      "Best Model: Lasso (L1) with CV score: 0.5486\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'C': 1}\n",
      "Best Parameters (Narrow Search): {'C': np.float64(2.575)}\n",
      "Test Set AUC (Final Model): 0.5726\n",
      "Test Set Accuracy (Final Model): 0.5461\n",
      "Confusion Matrix:\n",
      " [[29 38]\n",
      " [26 48]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.43      0.48        67\n",
      "           1       0.56      0.65      0.60        74\n",
      "\n",
      "    accuracy                           0.55       141\n",
      "   macro avg       0.54      0.54      0.54       141\n",
      "weighted avg       0.54      0.55      0.54       141\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.5206\n",
      "Model: Ridge Classifier, CV Score: 0.5188\n",
      "Model: Lasso (L1), CV Score: 0.5206\n",
      "Model: LDA, CV Score: 0.4726\n",
      "Model: Perceptron, CV Score: 0.4956\n",
      "Model: SVM (Linear), CV Score: 0.4797\n",
      "Model: Random Forest, CV Score: 0.5152\n",
      "Best Model: Logistic Regression with CV score: 0.5206\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'C': 100}\n",
      "Best Parameters (Narrow Search): {'C': np.float64(505.0)}\n",
      "Test Set AUC (Final Model): 0.5133\n",
      "Test Set Accuracy (Final Model): 0.5461\n",
      "Confusion Matrix:\n",
      " [[29 38]\n",
      " [26 48]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.43      0.48        67\n",
      "           1       0.56      0.65      0.60        74\n",
      "\n",
      "    accuracy                           0.55       141\n",
      "   macro avg       0.54      0.54      0.54       141\n",
      "weighted avg       0.54      0.55      0.54       141\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.5329\n",
      "Model: Ridge Classifier, CV Score: 0.5311\n",
      "Model: Lasso (L1), CV Score: 0.5491\n",
      "Model: LDA, CV Score: 0.4584\n",
      "Model: Perceptron, CV Score: 0.5187\n",
      "Model: SVM (Linear), CV Score: 0.5471\n",
      "Model: Random Forest, CV Score: 0.5294\n",
      "Best Model: Lasso (L1) with CV score: 0.5491\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'C': 100}\n",
      "Best Parameters (Narrow Search): {'C': np.float64(257.5)}\n",
      "Test Set AUC (Final Model): 0.5653\n",
      "Test Set Accuracy (Final Model): 0.5177\n",
      "Confusion Matrix:\n",
      " [[31 36]\n",
      " [32 42]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.46      0.48        67\n",
      "           1       0.54      0.57      0.55        74\n",
      "\n",
      "    accuracy                           0.52       141\n",
      "   macro avg       0.52      0.52      0.51       141\n",
      "weighted avg       0.52      0.52      0.52       141\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.5347\n",
      "Model: Ridge Classifier, CV Score: 0.5347\n",
      "Model: Lasso (L1), CV Score: 0.5562\n",
      "Model: LDA, CV Score: 0.4919\n",
      "Model: Perceptron, CV Score: 0.5098\n",
      "Model: SVM (Linear), CV Score: 0.5417\n",
      "Model: Random Forest, CV Score: 0.5242\n",
      "Best Model: Lasso (L1) with CV score: 0.5562\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'C': 1}\n",
      "Best Parameters (Narrow Search): {'C': np.float64(2.575)}\n",
      "Test Set AUC (Final Model): 0.5787\n",
      "Test Set Accuracy (Final Model): 0.5674\n",
      "Confusion Matrix:\n",
      " [[35 32]\n",
      " [29 45]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.52      0.53        67\n",
      "           1       0.58      0.61      0.60        74\n",
      "\n",
      "    accuracy                           0.57       141\n",
      "   macro avg       0.57      0.57      0.57       141\n",
      "weighted avg       0.57      0.57      0.57       141\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.5348\n",
      "Model: Ridge Classifier, CV Score: 0.5330\n",
      "Model: Lasso (L1), CV Score: 0.5507\n",
      "Model: LDA, CV Score: 0.4885\n",
      "Model: Perceptron, CV Score: 0.5508\n",
      "Model: SVM (Linear), CV Score: 0.5242\n",
      "Model: Random Forest, CV Score: 0.4996\n",
      "Best Model: Perceptron with CV score: 0.5508\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'alpha': 0.0001}\n",
      "Best Parameters (Narrow Search): {'alpha': np.float64(1e-05)}\n",
      "Model does not support probability predictions; skipping AUC computation.\n",
      "Test Set Accuracy (Final Model): 0.5106\n",
      "Confusion Matrix:\n",
      " [[ 9 58]\n",
      " [11 63]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.13      0.21        67\n",
      "           1       0.52      0.85      0.65        74\n",
      "\n",
      "    accuracy                           0.51       141\n",
      "   macro avg       0.49      0.49      0.43       141\n",
      "weighted avg       0.49      0.51      0.44       141\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.5347\n",
      "Model: Ridge Classifier, CV Score: 0.5364\n",
      "Model: Lasso (L1), CV Score: 0.5383\n",
      "Model: LDA, CV Score: 0.4674\n",
      "Model: Perceptron, CV Score: 0.5029\n",
      "Model: SVM (Linear), CV Score: 0.5472\n",
      "Model: Random Forest, CV Score: 0.5058\n",
      "Best Model: SVM (Linear) with CV score: 0.5472\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'C': 1}\n",
      "Best Parameters (Narrow Search): {'C': np.float64(2.575)}\n",
      "Model does not support probability predictions; skipping AUC computation.\n",
      "Test Set Accuracy (Final Model): 0.5106\n",
      "Confusion Matrix:\n",
      " [[24 43]\n",
      " [26 48]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.36      0.41        67\n",
      "           1       0.53      0.65      0.58        74\n",
      "\n",
      "    accuracy                           0.51       141\n",
      "   macro avg       0.50      0.50      0.50       141\n",
      "weighted avg       0.50      0.51      0.50       141\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.5362\n",
      "Model: Ridge Classifier, CV Score: 0.5326\n",
      "Model: Lasso (L1), CV Score: 0.5400\n",
      "Model: LDA, CV Score: 0.5293\n",
      "Model: Perceptron, CV Score: 0.5221\n",
      "Model: SVM (Linear), CV Score: 0.5006\n",
      "Model: Random Forest, CV Score: 0.4972\n",
      "Best Model: Lasso (L1) with CV score: 0.5400\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'C': 10}\n",
      "Best Parameters (Narrow Search): {'C': np.float64(25.75)}\n",
      "Test Set AUC (Final Model): 0.5065\n",
      "Test Set Accuracy (Final Model): 0.5035\n",
      "Confusion Matrix:\n",
      " [[32 35]\n",
      " [35 39]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.48      0.48        67\n",
      "           1       0.53      0.53      0.53        74\n",
      "\n",
      "    accuracy                           0.50       141\n",
      "   macro avg       0.50      0.50      0.50       141\n",
      "weighted avg       0.50      0.50      0.50       141\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.4953\n",
      "Model: Ridge Classifier, CV Score: 0.4988\n",
      "Model: Lasso (L1), CV Score: 0.5255\n",
      "Model: LDA, CV Score: 0.4778\n",
      "Model: Perceptron, CV Score: 0.5113\n",
      "Model: SVM (Linear), CV Score: 0.4793\n",
      "Model: Random Forest, CV Score: 0.5023\n",
      "Best Model: Lasso (L1) with CV score: 0.5255\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'C': 100}\n",
      "Best Parameters (Narrow Search): {'C': np.float64(257.5)}\n",
      "Test Set AUC (Final Model): 0.4877\n",
      "Test Set Accuracy (Final Model): 0.4681\n",
      "Confusion Matrix:\n",
      " [[28 39]\n",
      " [36 38]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.42      0.43        67\n",
      "           1       0.49      0.51      0.50        74\n",
      "\n",
      "    accuracy                           0.47       141\n",
      "   macro avg       0.47      0.47      0.47       141\n",
      "weighted avg       0.47      0.47      0.47       141\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.5260\n",
      "Model: Ridge Classifier, CV Score: 0.5225\n",
      "Model: Lasso (L1), CV Score: 0.5703\n",
      "Model: LDA, CV Score: 0.5066\n",
      "Model: Perceptron, CV Score: 0.5224\n",
      "Model: SVM (Linear), CV Score: 0.5278\n",
      "Model: Random Forest, CV Score: 0.5450\n",
      "Best Model: Lasso (L1) with CV score: 0.5703\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'C': 1}\n",
      "Best Parameters (Narrow Search): {'C': np.float64(5.05)}\n",
      "Test Set AUC (Final Model): 0.5537\n",
      "Test Set Accuracy (Final Model): 0.5319\n",
      "Confusion Matrix:\n",
      " [[30 37]\n",
      " [29 45]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.45      0.48        67\n",
      "           1       0.55      0.61      0.58        74\n",
      "\n",
      "    accuracy                           0.53       141\n",
      "   macro avg       0.53      0.53      0.53       141\n",
      "weighted avg       0.53      0.53      0.53       141\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.5061\n",
      "Model: Ridge Classifier, CV Score: 0.5079\n",
      "Model: Lasso (L1), CV Score: 0.5684\n",
      "Model: LDA, CV Score: 0.5045\n",
      "Model: Perceptron, CV Score: 0.5081\n",
      "Model: SVM (Linear), CV Score: 0.4689\n",
      "Model: Random Forest, CV Score: 0.5219\n",
      "Best Model: Lasso (L1) with CV score: 0.5684\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'C': 100}\n",
      "Best Parameters (Narrow Search): {'C': np.float64(257.5)}\n",
      "Test Set AUC (Final Model): 0.5262\n",
      "Test Set Accuracy (Final Model): 0.5390\n",
      "Confusion Matrix:\n",
      " [[29 38]\n",
      " [27 47]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.43      0.47        67\n",
      "           1       0.55      0.64      0.59        74\n",
      "\n",
      "    accuracy                           0.54       141\n",
      "   macro avg       0.54      0.53      0.53       141\n",
      "weighted avg       0.54      0.54      0.53       141\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.5132\n",
      "Model: Ridge Classifier, CV Score: 0.5079\n",
      "Model: Lasso (L1), CV Score: 0.5165\n",
      "Model: LDA, CV Score: 0.5132\n",
      "Model: Perceptron, CV Score: 0.4884\n",
      "Model: SVM (Linear), CV Score: 0.4883\n",
      "Model: Random Forest, CV Score: 0.5027\n",
      "Best Model: Lasso (L1) with CV score: 0.5165\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'C': 10}\n",
      "Best Parameters (Narrow Search): {'C': np.float64(25.75)}\n",
      "Test Set AUC (Final Model): 0.6404\n",
      "Test Set Accuracy (Final Model): 0.6383\n",
      "Confusion Matrix:\n",
      " [[34 33]\n",
      " [18 56]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.51      0.57        67\n",
      "           1       0.63      0.76      0.69        74\n",
      "\n",
      "    accuracy                           0.64       141\n",
      "   macro avg       0.64      0.63      0.63       141\n",
      "weighted avg       0.64      0.64      0.63       141\n",
      "\n",
      "Results for whole data_set1 model:\n",
      "Confusion Matrix:\n",
      " [[173 164]\n",
      " [107 260]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.62      0.51      0.56       337\n",
      "        True       0.61      0.71      0.66       367\n",
      "\n",
      "    accuracy                           0.62       704\n",
      "   macro avg       0.62      0.61      0.61       704\n",
      "weighted avg       0.62      0.62      0.61       704\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.5134\n",
      "Model: Ridge Classifier, CV Score: 0.5152\n",
      "Model: Lasso (L1), CV Score: 0.5543\n",
      "Model: LDA, CV Score: 0.5009\n",
      "Model: Perceptron, CV Score: 0.5222\n",
      "Model: SVM (Linear), CV Score: 0.4974\n",
      "Model: Random Forest, CV Score: 0.5261\n",
      "Best Model: Lasso (L1) with CV score: 0.5543\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'C': 100}\n",
      "Best Parameters (Narrow Search): {'C': np.float64(257.5)}\n",
      "Test Set AUC (Final Model): 0.5422\n",
      "Test Set Accuracy (Final Model): 0.5319\n",
      "Confusion Matrix:\n",
      " [[29 38]\n",
      " [28 46]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.43      0.47        67\n",
      "           1       0.55      0.62      0.58        74\n",
      "\n",
      "    accuracy                           0.53       141\n",
      "   macro avg       0.53      0.53      0.53       141\n",
      "weighted avg       0.53      0.53      0.53       141\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.5434\n",
      "Model: Ridge Classifier, CV Score: 0.5435\n",
      "Model: Lasso (L1), CV Score: 0.5346\n",
      "Model: LDA, CV Score: 0.5134\n",
      "Model: Perceptron, CV Score: 0.5292\n",
      "Model: SVM (Linear), CV Score: 0.5433\n",
      "Model: Random Forest, CV Score: 0.5220\n",
      "Best Model: Ridge Classifier with CV score: 0.5435\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Best Parameters (Broad Search): {'C': 1}\n",
      "Best Parameters (Narrow Search): {}\n",
      "Test Set AUC (Final Model): 0.5827\n",
      "Test Set Accuracy (Final Model): 0.5390\n",
      "Confusion Matrix:\n",
      " [[27 40]\n",
      " [25 49]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.40      0.45        67\n",
      "           1       0.55      0.66      0.60        74\n",
      "\n",
      "    accuracy                           0.54       141\n",
      "   macro avg       0.53      0.53      0.53       141\n",
      "weighted avg       0.54      0.54      0.53       141\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.5097\n",
      "Model: Ridge Classifier, CV Score: 0.5115\n",
      "Model: Lasso (L1), CV Score: 0.5331\n",
      "Model: LDA, CV Score: 0.4600\n",
      "Model: Perceptron, CV Score: 0.5116\n",
      "Model: SVM (Linear), CV Score: 0.5203\n",
      "Model: Random Forest, CV Score: 0.5153\n",
      "Best Model: Lasso (L1) with CV score: 0.5331\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'C': 1}\n",
      "Best Parameters (Narrow Search): {'C': np.float64(2.575)}\n",
      "Test Set AUC (Final Model): 0.6640\n",
      "Test Set Accuracy (Final Model): 0.6667\n",
      "Confusion Matrix:\n",
      " [[32 35]\n",
      " [12 62]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.48      0.58        67\n",
      "           1       0.64      0.84      0.73        74\n",
      "\n",
      "    accuracy                           0.67       141\n",
      "   macro avg       0.68      0.66      0.65       141\n",
      "weighted avg       0.68      0.67      0.65       141\n",
      "\n",
      "Results for whole data_set1 model:\n",
      "Confusion Matrix:\n",
      " [[160 177]\n",
      " [ 95 272]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.47      0.54       337\n",
      "        True       0.61      0.74      0.67       367\n",
      "\n",
      "    accuracy                           0.61       704\n",
      "   macro avg       0.62      0.61      0.60       704\n",
      "weighted avg       0.62      0.61      0.61       704\n",
      "\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T00:22:22.078418Z",
     "start_time": "2024-12-18T00:22:22.075978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "selected_feature_labels = [label for label, selected in zip(connectivity_labels, selected_features_data_set1) if selected]\n",
    "print(selected_feature_labels)"
   ],
   "id": "a742eb0972355eac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lh_dlPFC--THA-DP-lh', 'rh_dlPFC--THA-DP-lh', 'lh_mPFC--lAMY-rh', 'rh_mPFC--THA-DP-lh', 'lh_Ins--THA-DP-lh', 'rh_Ins--THA-DP-lh', 'THA-DP-rh--NAc-shell-rh', 'THA-VP-rh--THA-VA-rh', 'THA-VA-rh--THA-DP-lh', 'THA-DP-lh--THA-VA-lh']\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T00:20:49.144870Z",
     "start_time": "2024-12-18T00:20:49.133494Z"
    }
   },
   "cell_type": "code",
   "source": "connectivity_labels[selected_features_data_set1]",
   "id": "621a40cc930fc975",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[53], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mconnectivity_labels\u001B[49m\u001B[43m[\u001B[49m\u001B[43mselected_features_data_set1\u001B[49m\u001B[43m]\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T00:00:10.494860Z",
     "start_time": "2024-12-17T23:55:44.389517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_features = 10\n",
    "N_random_state = 0\n",
    "X_data_set1 = X_ih\n",
    "y_data_set1 = y_ih\n",
    "a = 0\n",
    "while a < 0.54: \n",
    "    final_model_data_set2, selected_features_data_set2, test_accuracy_data_set2 = pipeline1(X_data_set1, y_data_set1, n_features, N_random_state)\n",
    "    X_data_set1_selected = X_data_set1[:, selected_features_data_set1]\n",
    "    y_pred = final_model_data_set1.predict(X_data_set1_selected)\n",
    "    if test_accuracy_data_set1 >= 0.53:\n",
    "        print(\"Results for whole data_set1 model:\")\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set1, y_pred))\n",
    "        print(\"Classification Report:\\n\", classification_report(y_data_set1, y_pred))\n",
    "    a = test_accuracy_data_set2\n",
    "    N_random_state = N_random_state + 1"
   ],
   "id": "ffcc7c917b7c98c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression, CV Score: 0.4793\n",
      "Model: Ridge Classifier, CV Score: 0.4800\n",
      "Model: Lasso (L1), CV Score: 0.4786\n",
      "Model: LDA, CV Score: 0.4874\n",
      "Model: Perceptron, CV Score: 0.4911\n",
      "Model: SVM (Linear), CV Score: 0.4807\n",
      "Model: Random Forest, CV Score: 0.5022\n",
      "Best Model: Random Forest with CV score: 0.5022\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "Best Parameters (Broad Search): {'max_depth': None, 'n_estimators': 200}\n",
      "Best Parameters (Narrow Search): {'max_depth': None, 'n_estimators': 250}\n",
      "Test Set AUC (Final Model): 0.4962\n",
      "Test Set Accuracy (Final Model): 0.4926\n",
      "Confusion Matrix:\n",
      " [[77 87]\n",
      " [85 90]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.47      0.47       164\n",
      "           1       0.51      0.51      0.51       175\n",
      "\n",
      "    accuracy                           0.49       339\n",
      "   macro avg       0.49      0.49      0.49       339\n",
      "weighted avg       0.49      0.49      0.49       339\n",
      "\n",
      "Results for whole data_set1 model:\n",
      "Confusion Matrix:\n",
      " [[365 454]\n",
      " [350 524]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.45      0.48       819\n",
      "        True       0.54      0.60      0.57       874\n",
      "\n",
      "    accuracy                           0.53      1693\n",
      "   macro avg       0.52      0.52      0.52      1693\n",
      "weighted avg       0.52      0.53      0.52      1693\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.5096\n",
      "Model: Ridge Classifier, CV Score: 0.5096\n",
      "Model: Lasso (L1), CV Score: 0.4920\n",
      "Model: LDA, CV Score: 0.4875\n",
      "Model: Perceptron, CV Score: 0.5074\n",
      "Model: SVM (Linear), CV Score: 0.5074\n",
      "Model: Random Forest, CV Score: 0.5082\n",
      "Best Model: Logistic Regression with CV score: 0.5096\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'C': 1}\n",
      "Best Parameters (Narrow Search): {'C': np.float64(0.1)}\n",
      "Test Set AUC (Final Model): 0.5089\n",
      "Test Set Accuracy (Final Model): 0.4985\n",
      "Confusion Matrix:\n",
      " [[ 35 129]\n",
      " [ 41 134]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.21      0.29       164\n",
      "           1       0.51      0.77      0.61       175\n",
      "\n",
      "    accuracy                           0.50       339\n",
      "   macro avg       0.49      0.49      0.45       339\n",
      "weighted avg       0.49      0.50      0.46       339\n",
      "\n",
      "Results for whole data_set1 model:\n",
      "Confusion Matrix:\n",
      " [[365 454]\n",
      " [350 524]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.45      0.48       819\n",
      "        True       0.54      0.60      0.57       874\n",
      "\n",
      "    accuracy                           0.53      1693\n",
      "   macro avg       0.52      0.52      0.52      1693\n",
      "weighted avg       0.52      0.53      0.52      1693\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.4947\n",
      "Model: Ridge Classifier, CV Score: 0.4925\n",
      "Model: Lasso (L1), CV Score: 0.4778\n",
      "Model: LDA, CV Score: 0.4859\n",
      "Model: Perceptron, CV Score: 0.4859\n",
      "Model: SVM (Linear), CV Score: 0.4903\n",
      "Model: Random Forest, CV Score: 0.4971\n",
      "Best Model: Random Forest with CV score: 0.4971\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "Best Parameters (Broad Search): {'max_depth': 10, 'n_estimators': 100}\n",
      "Best Parameters (Narrow Search): {'max_depth': 10, 'n_estimators': 150}\n",
      "Test Set AUC (Final Model): 0.5466\n",
      "Test Set Accuracy (Final Model): 0.5369\n",
      "Confusion Matrix:\n",
      " [[ 80  84]\n",
      " [ 73 102]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.49      0.50       164\n",
      "           1       0.55      0.58      0.57       175\n",
      "\n",
      "    accuracy                           0.54       339\n",
      "   macro avg       0.54      0.54      0.53       339\n",
      "weighted avg       0.54      0.54      0.54       339\n",
      "\n",
      "Results for whole data_set1 model:\n",
      "Confusion Matrix:\n",
      " [[365 454]\n",
      " [350 524]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.45      0.48       819\n",
      "        True       0.54      0.60      0.57       874\n",
      "\n",
      "    accuracy                           0.53      1693\n",
      "   macro avg       0.52      0.52      0.52      1693\n",
      "weighted avg       0.52      0.53      0.52      1693\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.4955\n",
      "Model: Ridge Classifier, CV Score: 0.4941\n",
      "Model: Lasso (L1), CV Score: 0.5000\n",
      "Model: LDA, CV Score: 0.4925\n",
      "Model: Perceptron, CV Score: 0.5044\n",
      "Model: SVM (Linear), CV Score: 0.5022\n",
      "Model: Random Forest, CV Score: 0.5273\n",
      "Best Model: Random Forest with CV score: 0.5273\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "Best Parameters (Broad Search): {'max_depth': 10, 'n_estimators': 200}\n",
      "Best Parameters (Narrow Search): {'max_depth': 5, 'n_estimators': 200}\n",
      "Test Set AUC (Final Model): 0.4876\n",
      "Test Set Accuracy (Final Model): 0.5074\n",
      "Confusion Matrix:\n",
      " [[74 90]\n",
      " [77 98]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.45      0.47       164\n",
      "           1       0.52      0.56      0.54       175\n",
      "\n",
      "    accuracy                           0.51       339\n",
      "   macro avg       0.51      0.51      0.50       339\n",
      "weighted avg       0.51      0.51      0.51       339\n",
      "\n",
      "Results for whole data_set1 model:\n",
      "Confusion Matrix:\n",
      " [[365 454]\n",
      " [350 524]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.45      0.48       819\n",
      "        True       0.54      0.60      0.57       874\n",
      "\n",
      "    accuracy                           0.53      1693\n",
      "   macro avg       0.52      0.52      0.52      1693\n",
      "weighted avg       0.52      0.53      0.52      1693\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.5060\n",
      "Model: Ridge Classifier, CV Score: 0.5037\n",
      "Model: Lasso (L1), CV Score: 0.4852\n",
      "Model: LDA, CV Score: 0.4978\n",
      "Model: Perceptron, CV Score: 0.4889\n",
      "Model: SVM (Linear), CV Score: 0.5081\n",
      "Model: Random Forest, CV Score: 0.5126\n",
      "Best Model: Random Forest with CV score: 0.5126\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "Best Parameters (Broad Search): {'max_depth': None, 'n_estimators': 100}\n",
      "Best Parameters (Narrow Search): {'max_depth': None, 'n_estimators': 50}\n",
      "Test Set AUC (Final Model): 0.4959\n",
      "Test Set Accuracy (Final Model): 0.4897\n",
      "Confusion Matrix:\n",
      " [[73 91]\n",
      " [82 93]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.45      0.46       164\n",
      "           1       0.51      0.53      0.52       175\n",
      "\n",
      "    accuracy                           0.49       339\n",
      "   macro avg       0.49      0.49      0.49       339\n",
      "weighted avg       0.49      0.49      0.49       339\n",
      "\n",
      "Results for whole data_set1 model:\n",
      "Confusion Matrix:\n",
      " [[365 454]\n",
      " [350 524]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.45      0.48       819\n",
      "        True       0.54      0.60      0.57       874\n",
      "\n",
      "    accuracy                           0.53      1693\n",
      "   macro avg       0.52      0.52      0.52      1693\n",
      "weighted avg       0.52      0.53      0.52      1693\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.4912\n",
      "Model: Ridge Classifier, CV Score: 0.4926\n",
      "Model: Lasso (L1), CV Score: 0.4941\n",
      "Model: LDA, CV Score: 0.4890\n",
      "Model: Perceptron, CV Score: 0.4985\n",
      "Model: SVM (Linear), CV Score: 0.4867\n",
      "Model: Random Forest, CV Score: 0.4704\n",
      "Best Model: Perceptron with CV score: 0.4985\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'alpha': 0.0001}\n",
      "Best Parameters (Narrow Search): {'alpha': np.float64(1e-05)}\n",
      "Model does not support probability predictions; skipping AUC computation.\n",
      "Test Set Accuracy (Final Model): 0.5162\n",
      "Confusion Matrix:\n",
      " [[  0 164]\n",
      " [  0 175]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       164\n",
      "           1       0.52      1.00      0.68       175\n",
      "\n",
      "    accuracy                           0.52       339\n",
      "   macro avg       0.26      0.50      0.34       339\n",
      "weighted avg       0.27      0.52      0.35       339\n",
      "\n",
      "Results for whole data_set1 model:\n",
      "Confusion Matrix:\n",
      " [[365 454]\n",
      " [350 524]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.45      0.48       819\n",
      "        True       0.54      0.60      0.57       874\n",
      "\n",
      "    accuracy                           0.53      1693\n",
      "   macro avg       0.52      0.52      0.52      1693\n",
      "weighted avg       0.52      0.53      0.52      1693\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.5325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoqianxiao/Library/Caches/pypoetry/virtualenvs/ukbnexus-xiaoqian-PL9ZUpYW-py3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/xiaoqianxiao/Library/Caches/pypoetry/virtualenvs/ukbnexus-xiaoqian-PL9ZUpYW-py3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/xiaoqianxiao/Library/Caches/pypoetry/virtualenvs/ukbnexus-xiaoqian-PL9ZUpYW-py3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Ridge Classifier, CV Score: 0.5325\n",
      "Model: Lasso (L1), CV Score: 0.5347\n",
      "Model: LDA, CV Score: 0.5126\n",
      "Model: Perceptron, CV Score: 0.5200\n",
      "Model: SVM (Linear), CV Score: 0.5251\n",
      "Model: Random Forest, CV Score: 0.4927\n",
      "Best Model: Lasso (L1) with CV score: 0.5347\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'C': 1}\n",
      "Best Parameters (Narrow Search): {'C': np.float64(2.575)}\n",
      "Test Set AUC (Final Model): 0.4869\n",
      "Test Set Accuracy (Final Model): 0.4838\n",
      "Confusion Matrix:\n",
      " [[ 47 117]\n",
      " [ 58 117]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.29      0.35       164\n",
      "           1       0.50      0.67      0.57       175\n",
      "\n",
      "    accuracy                           0.48       339\n",
      "   macro avg       0.47      0.48      0.46       339\n",
      "weighted avg       0.47      0.48      0.46       339\n",
      "\n",
      "Results for whole data_set1 model:\n",
      "Confusion Matrix:\n",
      " [[365 454]\n",
      " [350 524]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.45      0.48       819\n",
      "        True       0.54      0.60      0.57       874\n",
      "\n",
      "    accuracy                           0.53      1693\n",
      "   macro avg       0.52      0.52      0.52      1693\n",
      "weighted avg       0.52      0.53      0.52      1693\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.4859\n",
      "Model: Ridge Classifier, CV Score: 0.4867\n",
      "Model: Lasso (L1), CV Score: 0.5044\n",
      "Model: LDA, CV Score: 0.4822\n",
      "Model: Perceptron, CV Score: 0.4948\n",
      "Model: SVM (Linear), CV Score: 0.4829\n",
      "Model: Random Forest, CV Score: 0.4934\n",
      "Best Model: Lasso (L1) with CV score: 0.5044\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'C': 1}\n",
      "Best Parameters (Narrow Search): {'C': np.float64(2.575)}\n",
      "Test Set AUC (Final Model): 0.4873\n",
      "Test Set Accuracy (Final Model): 0.4720\n",
      "Confusion Matrix:\n",
      " [[ 57 107]\n",
      " [ 72 103]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.35      0.39       164\n",
      "           1       0.49      0.59      0.54       175\n",
      "\n",
      "    accuracy                           0.47       339\n",
      "   macro avg       0.47      0.47      0.46       339\n",
      "weighted avg       0.47      0.47      0.46       339\n",
      "\n",
      "Results for whole data_set1 model:\n",
      "Confusion Matrix:\n",
      " [[365 454]\n",
      " [350 524]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.45      0.48       819\n",
      "        True       0.54      0.60      0.57       874\n",
      "\n",
      "    accuracy                           0.53      1693\n",
      "   macro avg       0.52      0.52      0.52      1693\n",
      "weighted avg       0.52      0.53      0.52      1693\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.4912\n",
      "Model: Ridge Classifier, CV Score: 0.4934\n",
      "Model: Lasso (L1), CV Score: 0.5089\n",
      "Model: LDA, CV Score: 0.4801\n",
      "Model: Perceptron, CV Score: 0.4926\n",
      "Model: SVM (Linear), CV Score: 0.5000\n",
      "Model: Random Forest, CV Score: 0.4808\n",
      "Best Model: Lasso (L1) with CV score: 0.5089\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'C': 1}\n",
      "Best Parameters (Narrow Search): {'C': np.float64(7.525)}\n",
      "Test Set AUC (Final Model): 0.4723\n",
      "Test Set Accuracy (Final Model): 0.4808\n",
      "Confusion Matrix:\n",
      " [[ 57 107]\n",
      " [ 69 106]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.35      0.39       164\n",
      "           1       0.50      0.61      0.55       175\n",
      "\n",
      "    accuracy                           0.48       339\n",
      "   macro avg       0.48      0.48      0.47       339\n",
      "weighted avg       0.48      0.48      0.47       339\n",
      "\n",
      "Results for whole data_set1 model:\n",
      "Confusion Matrix:\n",
      " [[365 454]\n",
      " [350 524]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.45      0.48       819\n",
      "        True       0.54      0.60      0.57       874\n",
      "\n",
      "    accuracy                           0.53      1693\n",
      "   macro avg       0.52      0.52      0.52      1693\n",
      "weighted avg       0.52      0.53      0.52      1693\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.5192\n",
      "Model: Ridge Classifier, CV Score: 0.5192\n",
      "Model: Lasso (L1), CV Score: 0.5097\n",
      "Model: LDA, CV Score: 0.5075\n",
      "Model: Perceptron, CV Score: 0.5266\n",
      "Model: SVM (Linear), CV Score: 0.5141\n",
      "Model: Random Forest, CV Score: 0.4970\n",
      "Best Model: Perceptron with CV score: 0.5266\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'alpha': 0.0001}\n",
      "Best Parameters (Narrow Search): {'alpha': np.float64(1e-05)}\n",
      "Model does not support probability predictions; skipping AUC computation.\n",
      "Test Set Accuracy (Final Model): 0.5280\n",
      "Confusion Matrix:\n",
      " [[ 56 108]\n",
      " [ 52 123]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.34      0.41       164\n",
      "           1       0.53      0.70      0.61       175\n",
      "\n",
      "    accuracy                           0.53       339\n",
      "   macro avg       0.53      0.52      0.51       339\n",
      "weighted avg       0.53      0.53      0.51       339\n",
      "\n",
      "Results for whole data_set1 model:\n",
      "Confusion Matrix:\n",
      " [[365 454]\n",
      " [350 524]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.45      0.48       819\n",
      "        True       0.54      0.60      0.57       874\n",
      "\n",
      "    accuracy                           0.53      1693\n",
      "   macro avg       0.52      0.52      0.52      1693\n",
      "weighted avg       0.52      0.53      0.52      1693\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.4749\n",
      "Model: Ridge Classifier, CV Score: 0.4749\n",
      "Model: Lasso (L1), CV Score: 0.4926\n",
      "Model: LDA, CV Score: 0.4676\n",
      "Model: Perceptron, CV Score: 0.4912\n",
      "Model: SVM (Linear), CV Score: 0.4705\n",
      "Model: Random Forest, CV Score: 0.4874\n",
      "Best Model: Lasso (L1) with CV score: 0.4926\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'C': 100}\n",
      "Best Parameters (Narrow Search): {'C': np.float64(257.5)}\n",
      "Test Set AUC (Final Model): 0.5068\n",
      "Test Set Accuracy (Final Model): 0.5074\n",
      "Confusion Matrix:\n",
      " [[ 72  92]\n",
      " [ 75 100]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.44      0.46       164\n",
      "           1       0.52      0.57      0.54       175\n",
      "\n",
      "    accuracy                           0.51       339\n",
      "   macro avg       0.51      0.51      0.50       339\n",
      "weighted avg       0.51      0.51      0.51       339\n",
      "\n",
      "Results for whole data_set1 model:\n",
      "Confusion Matrix:\n",
      " [[365 454]\n",
      " [350 524]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.45      0.48       819\n",
      "        True       0.54      0.60      0.57       874\n",
      "\n",
      "    accuracy                           0.53      1693\n",
      "   macro avg       0.52      0.52      0.52      1693\n",
      "weighted avg       0.52      0.53      0.52      1693\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.4779\n",
      "Model: Ridge Classifier, CV Score: 0.4786\n",
      "Model: Lasso (L1), CV Score: 0.4674\n",
      "Model: LDA, CV Score: 0.4764\n",
      "Model: Perceptron, CV Score: 0.4852\n",
      "Model: SVM (Linear), CV Score: 0.4845\n",
      "Model: Random Forest, CV Score: 0.4905\n",
      "Best Model: Random Forest with CV score: 0.4905\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "Best Parameters (Broad Search): {'max_depth': 20, 'n_estimators': 100}\n",
      "Best Parameters (Narrow Search): {'max_depth': 25, 'n_estimators': 50}\n",
      "Test Set AUC (Final Model): 0.4783\n",
      "Test Set Accuracy (Final Model): 0.4838\n",
      "Confusion Matrix:\n",
      " [[ 62 102]\n",
      " [ 73 102]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.38      0.41       164\n",
      "           1       0.50      0.58      0.54       175\n",
      "\n",
      "    accuracy                           0.48       339\n",
      "   macro avg       0.48      0.48      0.48       339\n",
      "weighted avg       0.48      0.48      0.48       339\n",
      "\n",
      "Results for whole data_set1 model:\n",
      "Confusion Matrix:\n",
      " [[365 454]\n",
      " [350 524]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.45      0.48       819\n",
      "        True       0.54      0.60      0.57       874\n",
      "\n",
      "    accuracy                           0.53      1693\n",
      "   macro avg       0.52      0.52      0.52      1693\n",
      "weighted avg       0.52      0.53      0.52      1693\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.4757\n",
      "Model: Ridge Classifier, CV Score: 0.4794\n",
      "Model: Lasso (L1), CV Score: 0.4772\n",
      "Model: LDA, CV Score: 0.4572\n",
      "Model: Perceptron, CV Score: 0.4808\n",
      "Model: SVM (Linear), CV Score: 0.4742\n",
      "Model: Random Forest, CV Score: 0.4749\n",
      "Best Model: Perceptron with CV score: 0.4808\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'alpha': 0.0001}\n",
      "Best Parameters (Narrow Search): {'alpha': np.float64(1e-05)}\n",
      "Model does not support probability predictions; skipping AUC computation.\n",
      "Test Set Accuracy (Final Model): 0.4985\n",
      "Confusion Matrix:\n",
      " [[142  22]\n",
      " [148  27]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.87      0.63       164\n",
      "           1       0.55      0.15      0.24       175\n",
      "\n",
      "    accuracy                           0.50       339\n",
      "   macro avg       0.52      0.51      0.43       339\n",
      "weighted avg       0.52      0.50      0.43       339\n",
      "\n",
      "Results for whole data_set1 model:\n",
      "Confusion Matrix:\n",
      " [[365 454]\n",
      " [350 524]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.45      0.48       819\n",
      "        True       0.54      0.60      0.57       874\n",
      "\n",
      "    accuracy                           0.53      1693\n",
      "   macro avg       0.52      0.52      0.52      1693\n",
      "weighted avg       0.52      0.53      0.52      1693\n",
      "\n",
      "Model: Logistic Regression, CV Score: 0.4986\n",
      "Model: Ridge Classifier, CV Score: 0.4986\n",
      "Model: Lasso (L1), CV Score: 0.5104\n",
      "Model: LDA, CV Score: 0.4860\n",
      "Model: Perceptron, CV Score: 0.4919\n",
      "Model: SVM (Linear), CV Score: 0.4971\n",
      "Model: Random Forest, CV Score: 0.4942\n",
      "Best Model: Lasso (L1) with CV score: 0.5104\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best Parameters (Broad Search): {'C': 10}\n",
      "Best Parameters (Narrow Search): {'C': np.float64(1.0)}\n",
      "Test Set AUC (Final Model): 0.5270\n",
      "Test Set Accuracy (Final Model): 0.5516\n",
      "Confusion Matrix:\n",
      " [[ 76  88]\n",
      " [ 64 111]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.46      0.50       164\n",
      "           1       0.56      0.63      0.59       175\n",
      "\n",
      "    accuracy                           0.55       339\n",
      "   macro avg       0.55      0.55      0.55       339\n",
      "weighted avg       0.55      0.55      0.55       339\n",
      "\n",
      "Results for whole data_set1 model:\n",
      "Confusion Matrix:\n",
      " [[365 454]\n",
      " [350 524]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.45      0.48       819\n",
      "        True       0.54      0.60      0.57       874\n",
      "\n",
      "    accuracy                           0.53      1693\n",
      "   macro avg       0.52      0.52      0.52      1693\n",
      "weighted avg       0.52      0.53      0.52      1693\n",
      "\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T00:07:00.204631Z",
     "start_time": "2024-12-18T00:07:00.198292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_data_set1 = X_ah\n",
    "y_data_set1 = y_ah\n",
    "X_data_set2 = X_ih\n",
    "y_data_set2 = y_ih\n",
    "X_data_set2_selected = X_data_set2[:, selected_features_data_set1]\n",
    "y_pred_data_set2 = final_model_data_set1.predict(X_data_set2_selected)\n",
    "accuracy = accuracy_score(y_data_set2, y_pred_data_set2)\n",
    "print(f\"Accuracy of data_set1 model on data_set2 data: {accuracy:.4f}\")\n",
    "# Check if the model supports probability predictions for AUC computation\n",
    "if hasattr(final_model_data_set1, \"predict_proba\"):\n",
    "    y_proba_data_set2 = final_model_data_set1.predict_proba(X_data_set2_selected)[:,\n",
    "                        1]  # Probabilities for the positive class\n",
    "    auc = roc_auc_score(y_data_set2, y_proba_data_set2)\n",
    "    print(f\"Dataset 2 - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "else:\n",
    "    print(f\"Dataset 2 - Accuracy: {accuracy:.4f}\")\n",
    "    auc = None  # AUC not computed due to lack of probability support\n",
    "print(\"\\nCalculating cosine similarity between data_set1 and data_set2 model weights:\")\n",
    "try:\n",
    "    similarity = calculate_model_similarity(final_model_data_set1, final_model_data_set2)\n",
    "    print(f\"Cosine similarity between data_set1 and data_set2 model weights: {similarity:.4f}\")\n",
    "except ValueError as e:\n",
    "    similarity = \"N/A (Model type not compatible for cosine similarity)\"\n",
    "    print(f\"Cosine similarity between data_set1 and data_set2 model weights: {similarity}\")"
   ],
   "id": "f7fb9a2913b029c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of data_set1 model on data_set2 data: 0.5251\n",
      "Dataset 2 - Accuracy: 0.5251, AUC: 0.5183\n",
      "\n",
      "Calculating cosine similarity between data_set1 and data_set2 model weights:\n",
      "Cosine similarity between data_set1 and data_set2 model weights: 0.1477\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_data_set2_selected = X_data_set2[:, selected_features_data_set1]\n",
    "    y_pred_data_set2 = final_model_data_set1.predict(X_data_set2_selected)\n",
    "    accuracy = accuracy_score(y_data_set2, y_pred_data_set2)\n",
    "    print(f\"Accuracy of data_set1 model on data_set2 data: {accuracy:.4f}\")\n",
    "    # Check if the model supports probability predictions for AUC computation\n",
    "    if hasattr(final_model_data_set1, \"predict_proba\"):\n",
    "        y_proba_data_set2 = final_model_data_set1.predict_proba(X_data_set2_selected)[:, 1]  # Probabilities for the positive class\n",
    "        auc = roc_auc_score(y_data_set2, y_proba_data_set2)\n",
    "        print(f\"Dataset 2 - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "    else:\n",
    "        print(f\"Dataset 2 - Accuracy: {accuracy:.4f}\")\n",
    "        auc = None  # AUC not computed due to lack of probability support\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set2, y_pred_data_set2))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_data_set2, y_pred_data_set2))\n",
    "\n",
    "    print(\"\\nCalculating cosine similarity between data_set1 and data_set2 model weights:\")\n",
    "    try:\n",
    "        similarity = calculate_model_similarity(final_model_data_set1, final_model_data_set2)\n",
    "        print(f\"Cosine similarity between data_set1 and data_set2 model weights: {similarity:.4f}\")\n",
    "    except ValueError as e:\n",
    "        similarity = \"N/A (Model type not compatible for cosine similarity)\"\n",
    "        print(f\"Cosine similarity between data_set1 and data_set2 model weights: {similarity}\")\n",
    "    return similarity, test_accuracy_data_set1, final_model_data_set1, test_accuracy_data_set2, final_model_data_set2, test_accuracy_all"
   ],
   "id": "e51d7caf816f13e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "85a326f59b8cd578"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
