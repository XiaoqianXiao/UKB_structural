{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T17:07:57.625962Z",
     "start_time": "2024-12-16T17:07:57.624262Z"
    }
   },
   "cell_type": "code",
   "source": "del list",
   "id": "e8b449e9734fbb45",
   "outputs": [],
   "execution_count": 461
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T21:09:31.226965Z",
     "start_time": "2024-12-19T21:09:31.223928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tian 1:10, 17:26\n",
    "subcortical_index = list(range(0,10)) + list(range(16,26))\n",
    "# Schaefer: \n",
    "# lh-mPFC: 199:205\n",
    "# rh-mPFC: 464:470\n",
    "# lh-Ins: 67, 108:111, 126:128\n",
    "# rh-Ins: 319, 361:364, 383:386\n",
    "## ACC: 390\n",
    "# Glasser\n",
    "cortical_roi = ['lh_dlPFC', 'rh_dlPFC', 'lh_mPFC', 'rh_mPFC', 'lh_PCC', 'rh_PCC', 'lh_Ins', 'rh_Ins']\n",
    "lh_dlPFC_index = [205, 246, 247, 249, 250, 252, 262, 263, 264, 265, 266, 276, 277]\n",
    "rh_dlPFC_index = [25, 66, 67, 69, 70, 72, 82, 83, 84, 85, 86, 96, 97]\n",
    "lh_mPFC_index = [236, 237, 238, 239, 240, 241, 242, 243, 244, 248, 267, 343, 344, 345, 358, 359]\n",
    "rh_mPFC_index = [56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 87, 163, 164, 165, 178, 179]\n",
    "lh_PCC_index = [193, 194, 206, 209, 210, 211, 212, 213, 214, 300, 321, 340, 341]\n",
    "rh_PCC_index = [13, 14, 26, 29, 30, 31, 32, 33, 34, 120, 141, 160, 161]\n",
    "lh_Ins_index = [285, 287, 288, 289, 290, 291, 293, 294, 346, 347, 348, 357]\n",
    "rh_Ins_index = [105, 107, 108, 109, 110, 111, 113, 114, 166, 167, 168, 177]\n",
    "dic_cortical_roi = {\n",
    "    'lh_dlPFC': lh_dlPFC_index,\n",
    "    'rh_dlPFC': rh_dlPFC_index,\n",
    "    'lh_mPFC': lh_mPFC_index,\n",
    "    'rh_mPFC': rh_mPFC_index,\n",
    "    'lh_PCC': lh_PCC_index,\n",
    "    'rh_PCC': rh_PCC_index,\n",
    "    'lh_Ins': lh_Ins_index,\n",
    "    'rh_Ins': rh_Ins_index\n",
    "}"
   ],
   "id": "5fc54c0c71675a67",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T21:09:32.360955Z",
     "start_time": "2024-12-19T21:09:32.173782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "\n",
    "# === Step 1: Define Functions === #\n",
    "\n",
    "def load_dataset(base_dir, data_set):\n",
    "    \"\"\"\n",
    "    Load dataset-specific files.\n",
    "    \"\"\"\n",
    "    fMRIinfo_file_path = os.path.join(base_dir, f\"{data_set}_data_set.csv\")\n",
    "    participant_file_path = os.path.join(base_dir, \"participants_fMRI.csv\")\n",
    "    return pd.read_csv(fMRIinfo_file_path), pd.read_csv(participant_file_path)\n",
    "\n",
    "\n",
    "def load_subject_timeseries(subject_ID, session_ID, derivatives_dir, dic_cortical_roi, subcortical_index):\n",
    "    \"\"\"\n",
    "    Load cortical and subcortical timeseries data for a subject.\n",
    "    \"\"\"\n",
    "    cortical_file_name = f\"sub-{subject_ID}_ses-{session_ID}_task-rest_space-Glasser.csv.gz\"\n",
    "    cortical_file_path = os.path.join(derivatives_dir, \"timeseries\", cortical_file_name)\n",
    "\n",
    "    subcortical_file_name = f\"sub-{subject_ID}_ses-{session_ID}_task-rest_space-Tian_Subcortex_S2_3T.csv.gz\"\n",
    "    subcortical_file_path = os.path.join(derivatives_dir, \"timeseries\", subcortical_file_name)\n",
    "\n",
    "    if not (os.path.exists(cortical_file_path) and os.path.exists(subcortical_file_path)):\n",
    "        print(f\"Missing files for subject {subject_ID}, session {session_ID}.\")\n",
    "        return None\n",
    "\n",
    "    # Load and process cortical timeseries\n",
    "    df_cortical_all = pd.read_csv(cortical_file_path, compression=\"gzip\", index_col=0, header=0)\n",
    "    df_cortical_roi = pd.DataFrame({\n",
    "        roi: df_cortical_all.iloc[dic_cortical_roi[roi]].mean(axis=0)\n",
    "        for roi in dic_cortical_roi.keys()\n",
    "    })\n",
    "\n",
    "    # Load and process subcortical timeseries\n",
    "    df_subcortical_all = pd.read_csv(subcortical_file_path, compression=\"gzip\", index_col=0, header=0)\n",
    "    df_subcortical_roi = df_subcortical_all.iloc[subcortical_index]\n",
    "\n",
    "    # Combine cortical and subcortical ROIs\n",
    "    return pd.concat([df_cortical_roi, df_subcortical_roi.transpose()], axis=1)\n",
    "\n",
    "\n",
    "def clean_data(data):\n",
    "    \"\"\"\n",
    "    Handle missing values and remove constant features from time series data.\n",
    "    \"\"\"\n",
    "    # Fill NaNs with column-wise means\n",
    "    data_filled = np.copy(data)\n",
    "    for j in range(data.shape[1]):\n",
    "        if np.isnan(data[:, j]).any():\n",
    "            data_filled[:, j] = np.nan_to_num(data[:, j], nan=np.nanmean(data[:, j]))\n",
    "\n",
    "    # Remove constant features\n",
    "    non_constant_features = data_filled[:, data_filled.std(axis=0) != 0]\n",
    "    return non_constant_features\n",
    "\n",
    "\n",
    "def compute_connectivity(data):\n",
    "    \"\"\"\n",
    "    Compute connectivity matrix for the given time series data.\n",
    "    \"\"\"\n",
    "    correlation_measure = ConnectivityMeasure(kind=\"correlation\")\n",
    "    return correlation_measure.fit_transform([data])[0]\n",
    "\n",
    "\n",
    "def extract_upper_triangle(matrix):\n",
    "    \"\"\"\n",
    "    Extract the upper triangle values (excluding diagonal) from a connectivity matrix.\n",
    "    \"\"\"\n",
    "    upper_tri_indices = np.triu_indices(matrix.shape[0], k=1)\n",
    "    return matrix[upper_tri_indices]\n",
    "\n",
    "\n",
    "# === Step 2: Define the Pipeline === #\n",
    "\n",
    "def process_fMRI_subject(subject_ID, session_ID, derivatives_dir, dic_cortical_roi, subcortical_index):\n",
    "    \"\"\"\n",
    "    Full pipeline for processing a single subject's fMRI data.\n",
    "    \"\"\"\n",
    "    # Load subject timeseries\n",
    "    df_roi = load_subject_timeseries(subject_ID, session_ID, derivatives_dir, dic_cortical_roi, subcortical_index)\n",
    "    if df_roi is None:\n",
    "        return None, None\n",
    "\n",
    "    # Clean data\n",
    "    #cleaned_data = clean_data(df_roi.values)\n",
    "\n",
    "    # Standardize data\n",
    "    standardized_data = StandardScaler().fit_transform(df_roi.values)\n",
    "\n",
    "    # Compute connectivity matrix\n",
    "    connectivity_matrix = compute_connectivity(standardized_data)\n",
    "\n",
    "    # Extract upper triangle\n",
    "    upper_triangle = extract_upper_triangle(connectivity_matrix)\n",
    "\n",
    "    return upper_triangle, subject_ID\n",
    "\n",
    "\n",
    "def process_fMRI_data(data_set, user_dir, project_name, session_ID, dic_cortical_roi, subcortical_index):\n",
    "    \"\"\"\n",
    "    Full pipeline for processing fMRI data for all subjects.\n",
    "    \"\"\"\n",
    "    # Set paths\n",
    "    base_dir = os.path.join(user_dir, project_name, \"data\")\n",
    "    derivatives_dir = os.path.join(base_dir, \"derivatives\")\n",
    "\n",
    "    # Load dataset\n",
    "    df_fMRIinfo, df_participants = load_dataset(base_dir, data_set)\n",
    "    subject_IDs = df_fMRIinfo[\"eid\"].unique()\n",
    "\n",
    "    # Initialize lists for data\n",
    "    connectivity_data = []\n",
    "    subject_ids_cleaned = []\n",
    "\n",
    "    # Process each subject individually\n",
    "    for subject_ID in subject_IDs:\n",
    "        upper_triangle, cleaned_subject_ID = process_fMRI_subject(\n",
    "            subject_ID, session_ID, derivatives_dir, dic_cortical_roi, subcortical_index\n",
    "        )\n",
    "        if upper_triangle is not None:\n",
    "            connectivity_data.append(upper_triangle)\n",
    "            subject_ids_cleaned.append(cleaned_subject_ID)\n",
    "\n",
    "    # Filter participants based on available data\n",
    "    df_filtered = df_participants.loc[df_participants[\"eid\"].isin(subject_ids_cleaned)]\n",
    "\n",
    "    return np.array(connectivity_data), df_filtered\n"
   ],
   "id": "c2c46bdad1394cae",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T21:09:47.935747Z",
     "start_time": "2024-12-19T21:09:47.861673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#codes for modeling\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Perform stratified 10-Fold Cross-Validation\n",
    "stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Ensure binary target\n",
    "def ensure_binary_target(y):\n",
    "    unique_values = np.unique(y)\n",
    "    if len(unique_values) > 2:\n",
    "        raise ValueError(\"Target variable contains more than two classes. Please preprocess the data.\")\n",
    "    if unique_values.dtype == bool:\n",
    "        return y.astype(int)\n",
    "    elif set(unique_values) == {0, 1} or set(unique_values) == {1, 0}:\n",
    "        return y\n",
    "    else:\n",
    "        raise ValueError(\"Target variable is not binary. Please preprocess the data.\")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split data into training and testing sets while preserving class distribution\n",
    "def split_data(X, y, N_random_state, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Split the data into training and testing sets while preserving class ratios.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Features.\n",
    "    - y: Target labels.\n",
    "    - test_size: Proportion of the dataset to include in the test split.\n",
    "    - random_state: Random state for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "    - X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=N_random_state, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "# Model selection using cross-validation\n",
    "def model_selection(X_train, y_train):\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(),  # Provides coefficients (coef_)\n",
    "        \"Ridge Classifier\": LogisticRegression(penalty='l2', solver='liblinear'),  # coef_\n",
    "        \"Lasso (L1)\": LogisticRegression(penalty='l1', solver='liblinear'),  # coef_\n",
    "        \"LDA\": LinearDiscriminantAnalysis(),  # Provides coefficients (coef_)\n",
    "        \"Perceptron\": Perceptron(),  # Provides coefficients (coef_)\n",
    "        \"SVM (Linear)\": SVC(kernel='linear'),  # Provides coefficients (coef_) when kernel='linear'\n",
    "        \"Random Forest\": RandomForestClassifier(),  # Provides feature_importances_\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "    best_score = -np.inf\n",
    "    best_name = \"\"\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        cv_score = cross_val_score(model, X_train, y_train, cv=stratified_kfold, scoring='accuracy').mean()\n",
    "        print(f\"Model: {model_name}, CV Score: {cv_score:.4f}\")\n",
    "\n",
    "        if cv_score > best_score:\n",
    "            best_score = cv_score\n",
    "            best_model = model\n",
    "            best_name = model_name\n",
    "\n",
    "    print(f\"Best Model: {best_name} with CV score: {best_score:.4f}\")\n",
    "    return best_model, best_name\n",
    "\n",
    "\n",
    "def feature_selection_with_ChiSquare(X, target, n_features):\n",
    "    from sklearn.feature_selection import SelectKBest, chi2\n",
    "    # Apply Chi-Square Test\n",
    "    X_shifted = X - X.min() + 1e-9\n",
    "    selector = SelectKBest(chi2, k=n_features)  # Select top 2 features\n",
    "    X_selected = selector.fit_transform(X_shifted, target)\n",
    "    \n",
    "    # Get boolean mask of selected features\n",
    "    selected_features_mask = selector.get_support()\n",
    "    \n",
    "    print(\"Selected Features Mask:\", selected_features_mask)\n",
    "    print(\"Scores:\\n\", selector.scores_)\n",
    "    return selected_features_mask\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "\n",
    "def feature_selection_with_rfe(X_train, y_train, n_features, best_model):\n",
    "    \"\"\"\n",
    "    Perform feature selection using RFE, with fallback to univariate selection for models without coefficients.\n",
    "    \"\"\"\n",
    "    if hasattr(best_model, \"coef_\") or hasattr(best_model, \"feature_importances_\"):\n",
    "        # Use RFE for models with coefficients or feature importances\n",
    "        rfe = RFE(estimator=best_model, n_features_to_select=n_features, step=1)\n",
    "        rfe.fit(X_train, y_train)\n",
    "\n",
    "        selected_features = rfe.support_\n",
    "        if np.sum(selected_features) == 0:\n",
    "            print(\"No features selected using RFE. Using all features as fallback.\")\n",
    "            selected_features = np.ones(X_train.shape[1], dtype=bool)\n",
    "\n",
    "    else:\n",
    "        # Fallback to univariate feature selection\n",
    "        print(\"Model lacks coefficients/feature importance; using univariate feature selection.\")\n",
    "        \n",
    "        # Use SelectKBest with F-statistic (or mutual information if preferred)\n",
    "        selector = SelectKBest(score_func=f_classif, k=n_features)\n",
    "        selector.fit(X_train, y_train)\n",
    "\n",
    "        selected_features = selector.get_support()\n",
    "        if np.sum(selected_features) == 0:\n",
    "            print(\"No features selected using univariate method. Using all features as fallback.\")\n",
    "            selected_features = np.ones(X_train.shape[1], dtype=bool)\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_classif\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "def feature_selection_with_rfe_cv(X_train, y_train, best_model, scoring_metric='accuracy'):\n",
    "    \"\"\"\n",
    "    Perform feature selection using RFE or univariate selection, optimizing the number of features automatically\n",
    "    using cross-validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def evaluate_features(model, X, y, num_features):\n",
    "        \"\"\"\n",
    "        Helper function to evaluate the model's performance with the given number of features using cross-validation.\n",
    "        \"\"\"\n",
    "        if hasattr(model, \"coef_\") or hasattr(model, \"feature_importances_\"):\n",
    "            # Perform RFE with the given number of features\n",
    "            rfe = RFE(estimator=model, n_features_to_select=num_features, step=1)\n",
    "            X_selected = rfe.fit_transform(X, y)\n",
    "        else:\n",
    "            # Use univariate feature selection as a fallback\n",
    "            selector = SelectKBest(score_func=f_classif, k=num_features)\n",
    "            X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "        # Evaluate model performance using cross-validation\n",
    "        scores = cross_val_score(model, X_selected, y, cv=stratified_kfold, scoring=scoring_metric)\n",
    "        return scores.mean()\n",
    "\n",
    "    # Iterate over a range of features to find the optimal number of features\n",
    "    best_score = -np.inf\n",
    "    optimal_num_features = 0\n",
    "    for num_features in range(1, X_train.shape[1] + 1):\n",
    "        score = evaluate_features(best_model, X_train, y_train, num_features)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            optimal_num_features = num_features\n",
    "\n",
    "    print(f\"Optimal number of features: {optimal_num_features} with cross-validated score: {best_score:.4f}\")\n",
    "\n",
    "    # Perform final RFE or univariate selection with the optimal number of features\n",
    "    if hasattr(best_model, \"coef_\") or hasattr(best_model, \"feature_importances_\"):\n",
    "        rfe = RFE(estimator=best_model, n_features_to_select=optimal_num_features, step=1)\n",
    "        rfe.fit(X_train, y_train)\n",
    "        selected_features = rfe.support_\n",
    "    else:\n",
    "        selector = SelectKBest(score_func=f_classif, k=optimal_num_features)\n",
    "        selector.fit(X_train, y_train)\n",
    "        selected_features = selector.get_support()\n",
    "\n",
    "    return selected_features, optimal_num_features\n",
    "\n",
    "\n",
    "# Two-step grid search for hyperparameter optimization\n",
    "def tune_model_hyperparameters(model, model_name, X_train, y_train):\n",
    "    refined_grid = {}  # Initialize with a default value to avoid \"unbound variable\" error\n",
    "\n",
    "    if model_name == \"Logistic Regression\":\n",
    "        broad_param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    elif model_name == \"Ridge Classifier\":\n",
    "        broad_param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    elif model_name == \"Lasso (L1)\" or model_name == \"ElasticNet (L1+L2)\":\n",
    "        broad_param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    elif model_name == \"SVM (Linear)\":\n",
    "        broad_param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    elif model_name == \"Random Forest\":\n",
    "        broad_param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30]}\n",
    "    elif model_name == \"Perceptron\":\n",
    "        broad_param_grid = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1]}\n",
    "    elif model_name == \"LDA\":\n",
    "        broad_param_grid = {'shrinkage': [None, 'auto'], 'solver': ['svd', 'lsqr', 'eigen']}\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} does not have a defined parameter grid.\")\n",
    "\n",
    "    # Broad Grid Search\n",
    "    broad_search = GridSearchCV(model, broad_param_grid, cv=stratified_kfold, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    broad_search.fit(X_train, y_train)\n",
    "    best_params_broad = broad_search.best_params_\n",
    "\n",
    "    # Define refined grid based on broad search results\n",
    "    if model_name in [\"Logistic Regression\", \"Lasso (L1)\", \"ElasticNet (L1+L2)\", \"SVM (Linear)\"]:\n",
    "        refined_grid = {'C': np.linspace(best_params_broad['C'] * 0.1, best_params_broad['C'] * 10, 5)}\n",
    "    elif model_name == \"Random Forest\":\n",
    "        refined_grid = {\n",
    "            'n_estimators': [max(10, best_params_broad['n_estimators'] - 50), best_params_broad['n_estimators'], best_params_broad['n_estimators'] + 50],\n",
    "            'max_depth': [None] if not best_params_broad['max_depth'] else [\n",
    "                max(1, best_params_broad['max_depth'] - 5), best_params_broad['max_depth'], best_params_broad['max_depth'] + 5]\n",
    "        }\n",
    "    elif model_name == \"Perceptron\":\n",
    "        refined_grid = {'alpha': np.linspace(best_params_broad['alpha'] * 0.1, best_params_broad['alpha'] * 10, 5)}\n",
    "    elif model_name == \"LDA\":\n",
    "        refined_grid = {'shrinkage': [best_params_broad['shrinkage']], 'solver': [best_params_broad['solver']]}\n",
    "\n",
    "    # Narrow Grid Search\n",
    "    narrow_search = GridSearchCV(model, refined_grid, cv=stratified_kfold, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    narrow_search.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Best Parameters (Broad Search): {best_params_broad}\")\n",
    "    print(f\"Best Parameters (Narrow Search): {narrow_search.best_params_}\")\n",
    "\n",
    "    best_model = narrow_search.best_estimator_\n",
    "    return best_model\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Train and evaluate final model\n",
    "def train_and_evaluate_final_model(X_train, y_train, X_test, y_test, model):\n",
    "    \"\"\"\n",
    "    Train and evaluate the final model. Reports accuracy and AUC.\n",
    "    Parameters:\n",
    "    - X_train: Features for training.\n",
    "    - y_train: Labels for training.\n",
    "    - X_test: Features for testing.\n",
    "    - y_test: Labels for testing.\n",
    "    - model: Machine learning model (must support `fit` and `predict_proba`).\n",
    "\n",
    "    Returns:\n",
    "    - model: Trained model.\n",
    "    - test_accuracy: Accuracy on the test set.\n",
    "    - test_auc: AUC score on the test set.\n",
    "    \"\"\"\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    \n",
    "    # Predict probabilities for AUC computation\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "        test_auc = roc_auc_score(y_test, y_proba)\n",
    "        print(f\"Test Set AUC (Final Model): {test_auc:.4f}\")\n",
    "    else:\n",
    "        print(\"Model does not support probability predictions; skipping AUC computation.\")\n",
    "        test_auc = None\n",
    "\n",
    "    print(f\"Test Set Accuracy (Final Model): {test_accuracy:.4f}\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    return model, test_accuracy, test_auc\n",
    "\n",
    "\n",
    "\n",
    "# Cosine similarity between two models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_model_similarity(model1, model2):\n",
    "    \"\"\"\n",
    "    Calculate the similarity between two models using cosine similarity or feature importances.\n",
    "\n",
    "    Parameters:\n",
    "    - model1: First trained model\n",
    "    - model2: Second trained model\n",
    "\n",
    "    Returns:\n",
    "    - similarity: Cosine similarity score between the two models' coefficients or importances.\n",
    "    \"\"\"\n",
    "    # Extract the weights (coefficients) or feature importances\n",
    "    def get_model_vector(model):\n",
    "        if hasattr(model, 'coef_'):  # Linear models with coefficients\n",
    "            return model.coef_.flatten()\n",
    "        elif hasattr(model, 'feature_importances_'):  # Tree-based models\n",
    "            return model.feature_importances_\n",
    "        else:\n",
    "            raise ValueError(f\"Model of type {type(model)} does not have coefficients or feature importances.\")\n",
    "    \n",
    "    try:\n",
    "        # Get vectors for the two models\n",
    "        vector1 = get_model_vector(model1)\n",
    "        vector2 = get_model_vector(model2)\n",
    "\n",
    "        # Ensure vectors are of the same length\n",
    "        if len(vector1) != len(vector2):\n",
    "            raise ValueError(\"Model vectors have different lengths. Ensure the models were trained on the same features.\")\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        similarity = cosine_similarity([vector1], [vector2])\n",
    "        return similarity[0][0]  # Return the scalar similarity value\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in calculating similarity: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Full pipeline\n",
    "def pipeline1(X, y, n_features, N_random_state):\n",
    "    y = ensure_binary_target(y)\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, N_random_state)\n",
    "\n",
    "    best_model, best_name = model_selection(X_train, y_train)\n",
    "\n",
    "    selected_features = feature_selection_with_rfe(X_train, y_train, n_features, best_model)\n",
    "    X_train_selected = X_train[:, selected_features]\n",
    "    X_test_selected = X_test[:, selected_features]\n",
    "\n",
    "    tuned_model = tune_model_hyperparameters(best_model, best_name, X_train_selected, y_train)\n",
    "\n",
    "    final_model, test_accuracy, test_auc = train_and_evaluate_final_model(\n",
    "        X_train_selected, y_train, X_test_selected, y_test, tuned_model\n",
    "    )\n",
    "    return final_model, selected_features, test_accuracy\n",
    "\n",
    "def pipeline2(X, y, N_random_state):\n",
    "    y = ensure_binary_target(y)\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, N_random_state)\n",
    "\n",
    "    best_model, best_name = model_selection(X_train, y_train)\n",
    "\n",
    "    \n",
    "    selected_features, features_number = feature_selection_with_rfe_cv(X_train, y_train, best_model)\n",
    "    X_train_selected = X_train[:, selected_features]\n",
    "    X_test_selected = X_test[:, selected_features]\n",
    "\n",
    "    tuned_model = tune_model_hyperparameters(best_model, best_name, X_train_selected, y_train)\n",
    "\n",
    "    final_model, test_accuracy, test_auc = train_and_evaluate_final_model(\n",
    "        X_train_selected, y_train, X_test_selected, y_test, tuned_model\n",
    "    )\n",
    "    return final_model, selected_features, test_accuracy\n",
    "\n",
    "\n",
    "def compare_models_and_analyze_topography1(X_data_set1, y_data_set1, X_data_set2, y_data_set2, n_features, N_random_state):\n",
    "    print(\"Training data_set1 model...\")\n",
    "    final_model_data_set1, selected_features_data_set1, test_accuracy_data_set1 = pipeline1(X_data_set1, y_data_set1, n_features, N_random_state)\n",
    "    #X_data_set1_selected = X_data_set1[:, selected_features_data_set1]\n",
    "    #y_pred = final_model_data_set1.predict(X_data_set1_selected)\n",
    "    # print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set1, y_pred))\n",
    "    # print(\"Classification Report:\\n\", classification_report(y_data_set1, y_pred))\n",
    "    if test_accuracy_data_set1 < 0.8:\n",
    "        print(f\"Test accuracy ({test_accuracy_data_set1:.4f}) is below 0.8. Stopping pipeline.\")\n",
    "        return None, test_accuracy_data_set1, None, None  # Early exit with placeholder return values\n",
    "    \n",
    "    print(\"\\nTraining data_set2 model...\")\n",
    "    final_model_data_set2, selected_features_data_set2, test_accuracy_data_set2 = pipeline1(X_data_set2, y_data_set2, n_features, N_random_state)\n",
    "    # X_data_set2_selected = X_data_set2[:, selected_features_data_set2]\n",
    "    # y_pred2 = final_model_data_set2.predict(X_data_set2_selected)\n",
    "    # print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set2, y_pred2))\n",
    "    # print(\"Classification Report:\\n\", classification_report(y_data_set2, y_pred2))\n",
    "    \n",
    "\n",
    "    print(\"\\nEvaluating data_set1 model on data_set2 dataset:\")\n",
    "    X_data_set2_selected = X_data_set2[:, selected_features_data_set1]\n",
    "    y_pred_data_set2 = final_model_data_set1.predict(X_data_set2_selected)\n",
    "    accuracy = accuracy_score(y_data_set2, y_pred_data_set2)\n",
    "    print(f\"Accuracy of data_set1 model on data_set2 data: {accuracy:.4f}\")\n",
    "    # Check if the model supports probability predictions for AUC computation\n",
    "    if hasattr(final_model_data_set1, \"predict_proba\"):\n",
    "        y_proba_data_set2 = final_model_data_set1.predict_proba(X_data_set2_selected)[:, 1]  # Probabilities for the positive class\n",
    "        auc = roc_auc_score(y_data_set2, y_proba_data_set2)\n",
    "        print(f\"Dataset 2 - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "    else:\n",
    "        print(f\"Dataset 2 - Accuracy: {accuracy:.4f}\")\n",
    "        auc = None  # AUC not computed due to lack of probability support\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set2, y_pred_data_set2))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_data_set2, y_pred_data_set2))\n",
    "\n",
    "    print(\"\\nCalculating cosine similarity between data_set1 and data_set2 model weights:\")\n",
    "    try:\n",
    "        similarity = calculate_model_similarity(final_model_data_set1, final_model_data_set2)\n",
    "        print(f\"Cosine similarity between data_set1 and data_set2 model weights: {similarity:.4f}\")\n",
    "    except ValueError as e:\n",
    "        similarity = \"N/A (Model type not compatible for cosine similarity)\"\n",
    "        print(f\"Cosine similarity between data_set1 and data_set2 model weights: {similarity}\")\n",
    "    return similarity, test_accuracy_data_set1, final_model_data_set1, final_model_data_set2\n",
    "\n",
    "\n",
    "\n",
    "def compare_models_and_analyze_topography2(X_data_set1, y_data_set1, X_data_set2, y_data_set2, N_random_state):\n",
    "    print(\"Training data_set1 model...\")\n",
    "    final_model_data_set1, selected_features_data_set1, test_accuracy_data_set1 = pipeline2(X_data_set1, y_data_set1, N_random_state)\n",
    "    # X_data_set1_selected = X_data_set1[:, selected_features_data_set1]\n",
    "    # y_pred = final_model_data_set1.predict(X_data_set1_selected)\n",
    "    # print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set1, y_pred))\n",
    "    # print(\"Classification Report:\\n\", classification_report(y_data_set1, y_pred))\n",
    "    \n",
    "    print(\"\\nTraining data_set2 model...\")\n",
    "    final_model_data_set2, selected_features_data_set2, test_accuracy_data_set2 = pipeline2(X_data_set2, y_data_set2, N_random_state)\n",
    "    # X_data_set2_selected = X_data_set2[:, selected_features_data_set2]\n",
    "    # y_pred2 = final_model_data_set2.predict(X_data_set2_selected)\n",
    "    # print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set2, y_pred2))\n",
    "    # print(\"Classification Report:\\n\", classification_report(y_data_set2, y_pred2))\n",
    "    \n",
    "\n",
    "    print(\"\\nEvaluating data_set1 model on data_set2 dataset:\")\n",
    "    X_data_set2_selected = X_data_set2[:, selected_features_data_set1]\n",
    "    y_pred_data_set2 = final_model_data_set1.predict(X_data_set2_selected)\n",
    "    accuracy = accuracy_score(y_data_set2, y_pred_data_set2)\n",
    "    print(f\"Accuracy of data_set1 model on data_set2 data: {accuracy:.4f}\")\n",
    "    # Check if the model supports probability predictions for AUC computation\n",
    "    if hasattr(final_model_data_set1, \"predict_proba\"):\n",
    "        y_proba_data_set2 = final_model_data_set1.predict_proba(X_data_set2_selected)[:, 1]  # Probabilities for the positive class\n",
    "        auc = roc_auc_score(y_data_set2, y_proba_data_set2)\n",
    "        print(f\"Dataset 2 - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "    else:\n",
    "        print(f\"Dataset 2 - Accuracy: {accuracy:.4f}\")\n",
    "        auc = None  # AUC not computed due to lack of probability support\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set2, y_pred_data_set2))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_data_set2, y_pred_data_set2))\n",
    "\n",
    "    print(\"\\nCalculating cosine similarity between data_set1 and data_set2 model weights:\")\n",
    "    try:\n",
    "        similarity = calculate_model_similarity(final_model_data_set1, final_model_data_set2)\n",
    "        print(f\"Cosine similarity between data_set1 and data_set2 model weights: {similarity:.4f}\")\n",
    "    except ValueError as e:\n",
    "        similarity = \"N/A (Model type not compatible for cosine similarity)\"\n",
    "        print(f\"Cosine similarity between data_set1 and data_set2 model weights: {similarity}\")\n",
    "    return similarity, test_accuracy_data_set1"
   ],
   "id": "53f841406272c9d6",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T21:09:51.511931Z",
     "start_time": "2024-12-19T21:09:51.510371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define user inputs\n",
    "user_dir = \"/Users/xiaoqianxiao\"\n",
    "project_name = \"UKB\"\n",
    "session_ID = 2  # Specify session"
   ],
   "id": "d5f513afe68162b6",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T17:34:15.410890Z",
     "start_time": "2024-12-17T17:33:12.403014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run the pipeline\n",
    "data_set = \"past_anxiety\"  # Dataset identifier\n",
    "X_pad, df_PAD = process_fMRI_data(data_set, user_dir, project_name, session_ID, dic_cortical_roi, subcortical_index)\n",
    "y_pad = df_PAD[\"hospital_not_now\"]\n",
    "y_pad_GAD7 = df_PAD[\"GAD7_score\"]\n",
    "\n",
    "data_set = \"current_anxiety\"  # Dataset identifier\n",
    "X_cad, df_CAD = process_fMRI_data(data_set, user_dir, project_name, session_ID, dic_cortical_roi, subcortical_index)\n",
    "y_cad = df_CAD[\"hospital_current_anxiety\"]\n",
    "y_cad_GAD7 = df_CAD[\"GAD7_score\"]"
   ],
   "id": "2fdce368bac9cc64",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T19:43:35.554260Z",
     "start_time": "2024-12-16T19:43:35.550760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'n(cad)/(cad_control): {sum(y_cad==True)}/{sum(y_cad==False)} = {((sum(y_cad==True))/(sum(y_cad==False))):.2f}')\n",
    "print(f'n(pad)/(pad_control): {sum(y_pad==True)}/{sum(y_pad==False)} = {((sum(y_pad==True))/(sum(y_pad==False))):.2f}')"
   ],
   "id": "48b294ec0ab1a0b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n(cad)/(cad_control): 118/106 = 1.11\n",
      "n(pad)/(pad_control): 511/478 = 1.07\n"
     ]
    }
   ],
   "execution_count": 498
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_features = 20\n",
    "compare_models_and_analyze_topography1(X_cad, y_cad, X_pad, y_pad, n_features)"
   ],
   "id": "c63bfa9a0c704d13"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "a = 0\n",
    "N_random_state = 0\n",
    "while a < 0.8:\n",
    "    n_features = 10\n",
    "    similarity, test_accuracy_data_set1, final_model_data_set1, final_model_data_set2 = compare_models_and_analyze_topography1(X_cad, y_cad, X_pad, y_pad, n_features,N_random_state)\n",
    "    a = test_accuracy_data_set1\n",
    "    print(N_random_state)\n",
    "    print(test_accuracy_data_set1)\n",
    "    N_random_state = N_random_state + 1"
   ],
   "id": "805dddcfcfe7e3df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "similarity, test_accuracy_data_set1 = compare_models_and_analyze_topography2(X_cad, y_cad, X_pad, y_pad)",
   "id": "c6b1a5b241ee0969"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T21:11:25.371527Z",
     "start_time": "2024-12-19T21:09:58.904822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_set = \"ah\"  # Dataset identifier\n",
    "X_ah, df_ah = process_fMRI_data(data_set, user_dir, project_name, session_ID, dic_cortical_roi, subcortical_index)\n",
    "y_ah = df_ah[\"active_history\"]\n",
    "\n",
    "data_set = \"ih\"  # Dataset identifier\n",
    "X_ih, df_ih = process_fMRI_data(data_set, user_dir, project_name, session_ID, dic_cortical_roi, subcortical_index)\n",
    "y_ih = df_ih[\"inactive_history\"]\n",
    "\n",
    "data_set = \"a_noh\"  # Dataset identifier\n",
    "X_a_noh, df_a_noh = process_fMRI_data(data_set, user_dir, project_name, session_ID, dic_cortical_roi, subcortical_index)\n",
    "y_a_noh = df_a_noh[\"active_no_history\"]"
   ],
   "id": "f7b9d64c4a1a48d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files for subject 1529291, session 2.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T21:12:51.459702Z",
     "start_time": "2024-12-19T21:12:51.456859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'n(ah)/(ah_control): {sum(y_ah==True)}/{sum(y_ah==False)} = {((sum(y_ah==True))/(sum(y_ah==False))):.2f}')\n",
    "print(f'n(ih)/(ih_control): {sum(y_ih==True)}/{sum(y_ih==False)} = {((sum(y_ih==True))/(sum(y_ih==False))):.2f}')\n",
    "print(f'n(a_noh)/(a_noh_control): {sum(y_a_noh==True)}/{sum(y_a_noh==False)} = {((sum(y_a_noh==True))/(sum(y_a_noh==False))):.2f}')"
   ],
   "id": "e69030102072c264",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n(ah)/(ah_control): 367/337 = 1.09\n",
      "n(ih)/(ih_control): 874/819 = 1.07\n",
      "n(a_noh)/(a_noh_control): 250/233 = 1.07\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "a = 0\n",
    "N_random_state = 0\n",
    "while a < 0.7:\n",
    "    n_features = 10\n",
    "    #9 for ah\n",
    "    similarity, test_accuracy_data_set1 = compare_models_and_analyze_topography1(X_ah, y_ah, X_ih, y_ih, n_features, N_random_state)\n",
    "    a = test_accuracy_data_set1\n",
    "    print(N_random_state)\n",
    "    print(test_accuracy_data_set1)\n",
    "    N_random_state = N_random_state + 1"
   ],
   "id": "5225ac2416aa7dcc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "compare_models_and_analyze_topography2(X_ah, y_ah, X_ih, y_ih)",
   "id": "c370a683668eb15a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "a = 0\n",
    "N_random_state = 0\n",
    "while a < 0.8:\n",
    "    n_features = 10\n",
    "    similarity, test_accuracy_data_set1 = compare_models_and_analyze_topography1(X_ah, y_ah, X_a_noh, y_a_noh, n_features,N_random_state)\n",
    "    a = test_accuracy_data_set1\n",
    "    print(N_random_state)\n",
    "    print(test_accuracy_data_set1)\n",
    "    N_random_state = N_random_state + 1"
   ],
   "id": "228439085d61af4b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "compare_models_and_analyze_topography2(X_ah, y_ah, X_a_noh, y_a_noh)",
   "id": "1d2b698a428fc652"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Apply PCA\n",
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Determine the number of components to retain\n",
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "n_components = np.argmax(explained_variance >= 0.95) + 1  # Keep components that explain 95% variance\n",
    "\n",
    "# Use the selected components\n",
    "X_train_selected = X_train_pca[:, :n_components]\n",
    "X_test_selected = X_test_pca[:, :n_components]"
   ],
   "id": "25410d07d9fd95e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T21:24:41.180619Z",
     "start_time": "2024-12-19T21:24:41.177781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def pipeline4(X, y):\n",
    "    y = ensure_binary_target(y)\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, N_random_state=422)\n",
    "    # Apply PCA\n",
    "    pca = PCA()\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    # Determine the number of components to retain\n",
    "    explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "    n_components = np.argmax(explained_variance >= 0.99) + 1  # Keep components that explain 95% variance\n",
    "    \n",
    "    # Use the selected components\n",
    "    X_train_selected = X_train_pca[:, :n_components]\n",
    "    X_test_selected = X_test_pca[:, :n_components]\n",
    "\n",
    "    best_model, best_name = model_selection(X_train_selected, y_train)\n",
    "\n",
    "    tuned_model = tune_model_hyperparameters(best_model, best_name, X_train_selected, y_train)\n",
    "\n",
    "    final_model, test_accuracy, test_auc = train_and_evaluate_final_model(\n",
    "        X_train_selected, y_train, X_test_selected, y_test, tuned_model\n",
    "    )\n",
    "    return final_model, test_accuracy, test_auc, n_components"
   ],
   "id": "b072a8a2178ab82e",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T21:25:27.219172Z",
     "start_time": "2024-12-19T21:25:16.299395Z"
    }
   },
   "cell_type": "code",
   "source": "final_model, test_accuracy, test_auc, n_components = pipeline4(X_ah, y_ah)",
   "id": "496bb085ae073e8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression, CV Score: 0.5240\n",
      "Model: Ridge Classifier, CV Score: 0.5222\n",
      "Model: Lasso (L1), CV Score: 0.5381\n",
      "Model: LDA, CV Score: 0.4921\n",
      "Model: Perceptron, CV Score: 0.5008\n",
      "Model: SVM (Linear), CV Score: 0.5348\n",
      "Model: Random Forest, CV Score: 0.5506\n",
      "Best Model: Random Forest with CV score: 0.5506\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "Best Parameters (Broad Search): {'max_depth': None, 'n_estimators': 200}\n",
      "Best Parameters (Narrow Search): {'max_depth': None, 'n_estimators': 150}\n",
      "Test Set AUC (Final Model): 0.5457\n",
      "Test Set Accuracy (Final Model): 0.4965\n",
      "Confusion Matrix:\n",
      " [[26 41]\n",
      " [30 44]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.39      0.42        67\n",
      "           1       0.52      0.59      0.55        74\n",
      "\n",
      "    accuracy                           0.50       141\n",
      "   macro avg       0.49      0.49      0.49       141\n",
      "weighted avg       0.49      0.50      0.49       141\n",
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T21:24:57.599447Z",
     "start_time": "2024-12-19T21:24:57.597989Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c6a6e3acd8a0e219",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a4883860c11599ce"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
