{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T21:51:52.260683Z",
     "start_time": "2025-02-12T21:51:52.258262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "id": "aca6b384ef5ba04",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-12T21:51:54.301988Z",
     "start_time": "2025-02-12T21:51:54.297984Z"
    }
   },
   "source": [
    "# Tian 1:10, 17:26\n",
    "subcortical_index = list(range(0,10)) + list(range(16,26))\n",
    "# Schaefer: \n",
    "# lh-mPFC: 199:205\n",
    "# rh-mPFC: 464:470\n",
    "# lh-Ins: 67, 108:111, 126:128\n",
    "# rh-Ins: 319, 361:364, 383:386\n",
    "## ACC: 390\n",
    "# Glasser\n",
    "cortical_roi = ['lh_dlPFC', 'rh_dlPFC', 'lh_mPFC', 'rh_mPFC', 'lh_PCC', 'rh_PCC', 'lh_Ins', 'rh_Ins']\n",
    "lh_dlPFC_index = [205, 246, 247, 249, 250, 252, 262, 263, 264, 265, 266, 276, 277]\n",
    "rh_dlPFC_index = [25, 66, 67, 69, 70, 72, 82, 83, 84, 85, 86, 96, 97]\n",
    "lh_mPFC_index = [236, 237, 238, 239, 240, 241, 242, 243, 244, 248, 267, 343, 344, 345, 358, 359]\n",
    "rh_mPFC_index = [56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 87, 163, 164, 165, 178, 179]\n",
    "lh_PCC_index = [193, 194, 206, 209, 210, 211, 212, 213, 214, 300, 321, 340, 341]\n",
    "rh_PCC_index = [13, 14, 26, 29, 30, 31, 32, 33, 34, 120, 141, 160, 161]\n",
    "lh_Ins_index = [285, 287, 288, 289, 290, 291, 293, 294, 346, 347, 348, 357]\n",
    "rh_Ins_index = [105, 107, 108, 109, 110, 111, 113, 114, 166, 167, 168, 177]\n",
    "dic_cortical_roi = {\n",
    "    'lh_dlPFC': lh_dlPFC_index,\n",
    "    'rh_dlPFC': rh_dlPFC_index,\n",
    "    'lh_mPFC': lh_mPFC_index,\n",
    "    'rh_mPFC': rh_mPFC_index,\n",
    "    'lh_PCC': lh_PCC_index,\n",
    "    'rh_PCC': rh_PCC_index,\n",
    "    'lh_Ins': lh_Ins_index,\n",
    "    'rh_Ins': rh_Ins_index\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T21:51:55.164022Z",
     "start_time": "2025-02-12T21:51:55.152250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "parcellation_dir = '/Users/xiaoqianxiao/tool/parcellation'\n",
    "sub_cortical_filename = 'Tian_Subcortex_S2_3T_label.csv'\n",
    "sub_cortical_file_path = os.path.join(parcellation_dir, sub_cortical_filename)\n",
    "df_sub_cortical_name = pd.read_csv(sub_cortical_file_path, header=None)\n",
    "df_sub_cortical_roi_name_need = df_sub_cortical_name.iloc[subcortical_index,0]\n",
    "df_cortical_roi_name = pd.DataFrame(cortical_roi)\n",
    "df_roi_name = pd.concat([df_cortical_roi_name, df_sub_cortical_roi_name_need],ignore_index=True)\n",
    "df_roi_name.columns = ['roi_name']\n",
    "from itertools import combinations\n",
    "combinations_list = list(combinations(df_roi_name['roi_name'], 2))\n",
    "df_roi_combinations = pd.DataFrame(combinations_list, columns=['ROI1', 'ROI2'])\n",
    "print(df_roi_combinations)"
   ],
   "id": "394006ffed88da69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ROI1          ROI2\n",
      "0        lh_dlPFC      rh_dlPFC\n",
      "1        lh_dlPFC       lh_mPFC\n",
      "2        lh_dlPFC       rh_mPFC\n",
      "3        lh_dlPFC        lh_PCC\n",
      "4        lh_dlPFC        rh_PCC\n",
      "..            ...           ...\n",
      "373     lh_THA-VA  lh_NAc-shell\n",
      "374     lh_THA-VA   lh_NAc-cole\n",
      "375     lh_THA-DA  lh_NAc-shell\n",
      "376     lh_THA-DA   lh_NAc-cole\n",
      "377  lh_NAc-shell   lh_NAc-cole\n",
      "\n",
      "[378 rows x 2 columns]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T21:52:02.805506Z",
     "start_time": "2025-02-12T21:52:01.923555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "\n",
    "# === Step 1: Define Functions === #\n",
    "\n",
    "def load_dataset(base_dir, data_set):\n",
    "    \"\"\"\n",
    "    Load dataset-specific files.\n",
    "    \"\"\"\n",
    "    fMRIinfo_file_path = os.path.join(base_dir, f\"{data_set}_data_set.csv\")\n",
    "    participant_file_path = os.path.join(base_dir, \"participants_fMRI.csv\")\n",
    "    return pd.read_csv(fMRIinfo_file_path), pd.read_csv(participant_file_path)\n",
    "\n",
    "\n",
    "def load_subject_timeseries(subject_ID, session_ID, derivatives_dir, dic_cortical_roi, subcortical_index):\n",
    "    \"\"\"\n",
    "    Load cortical and subcortical timeseries data for a subject.\n",
    "    \"\"\"\n",
    "    cortical_file_name = f\"sub-{subject_ID}_ses-{session_ID}_task-rest_space-Glasser.csv.gz\"\n",
    "    cortical_file_path = os.path.join(derivatives_dir, \"timeseries\", cortical_file_name)\n",
    "\n",
    "    subcortical_file_name = f\"sub-{subject_ID}_ses-{session_ID}_task-rest_space-Tian_Subcortex_S2_3T.csv.gz\"\n",
    "    subcortical_file_path = os.path.join(derivatives_dir, \"timeseries\", subcortical_file_name)\n",
    "\n",
    "    if not (os.path.exists(cortical_file_path) and os.path.exists(subcortical_file_path)):\n",
    "        print(f\"Missing files for subject {subject_ID}, session {session_ID}.\")\n",
    "        return None\n",
    "\n",
    "    # Load and process cortical timeseries\n",
    "    df_cortical_all = pd.read_csv(cortical_file_path, compression=\"gzip\", index_col=0, header=0)\n",
    "    df_cortical_roi = pd.DataFrame({\n",
    "        roi: df_cortical_all.iloc[dic_cortical_roi[roi]].mean(axis=0)\n",
    "        for roi in dic_cortical_roi.keys()\n",
    "    })\n",
    "\n",
    "    # Load and process subcortical timeseries\n",
    "    df_subcortical_all = pd.read_csv(subcortical_file_path, compression=\"gzip\", index_col=0, header=0)\n",
    "    df_subcortical_roi = df_subcortical_all.iloc[subcortical_index]\n",
    "\n",
    "    # Combine cortical and subcortical ROIs\n",
    "    return pd.concat([df_cortical_roi, df_subcortical_roi.transpose()], axis=1)\n",
    "\n",
    "\n",
    "def clean_data(data):\n",
    "    \"\"\"\n",
    "    Handle missing values and remove constant features from time series data.\n",
    "    \"\"\"\n",
    "    # Fill NaNs with column-wise means\n",
    "    data_filled = np.copy(data)\n",
    "    for j in range(data.shape[1]):\n",
    "        if np.isnan(data[:, j]).any():\n",
    "            data_filled[:, j] = np.nan_to_num(data[:, j], nan=np.nanmean(data[:, j]))\n",
    "\n",
    "    # Remove constant features\n",
    "    non_constant_features = data_filled[:, data_filled.std(axis=0) != 0]\n",
    "    return non_constant_features\n",
    "\n",
    "\n",
    "def compute_connectivity(data):\n",
    "    \"\"\"\n",
    "    Compute connectivity matrix for the given time series data.\n",
    "    \"\"\"\n",
    "    correlation_measure = ConnectivityMeasure(kind=\"correlation\")\n",
    "    return correlation_measure.fit_transform([data])[0]\n",
    "\n",
    "\n",
    "def extract_upper_triangle(matrix):\n",
    "    \"\"\"\n",
    "    Extract the upper triangle values (excluding diagonal) from a connectivity matrix.\n",
    "    \"\"\"\n",
    "    upper_tri_indices = np.triu_indices(matrix.shape[0], k=1)\n",
    "    return matrix[upper_tri_indices]\n",
    "\n",
    "\n",
    "# === Step 2: Define the Pipeline === #\n",
    "\n",
    "def process_fMRI_subject(subject_ID, session_ID, derivatives_dir, dic_cortical_roi, subcortical_index):\n",
    "    \"\"\"\n",
    "    Full pipeline for processing a single subject's fMRI data.\n",
    "    \"\"\"\n",
    "    # Load subject timeseries\n",
    "    df_roi = load_subject_timeseries(subject_ID, session_ID, derivatives_dir, dic_cortical_roi, subcortical_index)\n",
    "    if df_roi is None:\n",
    "        return None, None\n",
    "\n",
    "    # Clean data\n",
    "    #cleaned_data = clean_data(df_roi.values)\n",
    "\n",
    "    # Standardize data\n",
    "    standardized_data = StandardScaler().fit_transform(df_roi.values)\n",
    "\n",
    "    # Compute connectivity matrix\n",
    "    connectivity_matrix = compute_connectivity(standardized_data)\n",
    "\n",
    "    # Extract upper triangle\n",
    "    upper_triangle = extract_upper_triangle(connectivity_matrix)\n",
    "\n",
    "    return upper_triangle, subject_ID\n",
    "\n",
    "\n",
    "def process_fMRI_data(data_set, user_dir, project_name, session_ID, dic_cortical_roi, subcortical_index):\n",
    "    \"\"\"\n",
    "    Full pipeline for processing fMRI data for all subjects.\n",
    "    \"\"\"\n",
    "    # Set paths\n",
    "    base_dir = os.path.join(user_dir, project_name, \"data\")\n",
    "    derivatives_dir = os.path.join(base_dir, \"derivatives\")\n",
    "\n",
    "    # Load dataset\n",
    "    df_fMRIinfo, df_participants = load_dataset(base_dir, data_set)\n",
    "    subject_IDs = df_fMRIinfo[\"eid\"].unique()\n",
    "\n",
    "    # Initialize lists for data\n",
    "    connectivity_data = []\n",
    "    subject_ids_cleaned = []\n",
    "\n",
    "    # Process each subject individually\n",
    "    for subject_ID in subject_IDs:\n",
    "        upper_triangle, cleaned_subject_ID = process_fMRI_subject(\n",
    "            subject_ID, session_ID, derivatives_dir, dic_cortical_roi, subcortical_index\n",
    "        )\n",
    "        if upper_triangle is not None:\n",
    "            connectivity_data.append(upper_triangle)\n",
    "            subject_ids_cleaned.append(cleaned_subject_ID)\n",
    "\n",
    "    # Filter participants based on available data\n",
    "    df_filtered = df_participants.loc[df_participants[\"eid\"].isin(subject_ids_cleaned)]\n",
    "\n",
    "    return np.array(connectivity_data), df_filtered\n"
   ],
   "id": "2f4bf04b701b6ab7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T21:52:08.929270Z",
     "start_time": "2025-02-12T21:52:08.657067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#codes for modeling\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Perform stratified 10-Fold Cross-Validation\n",
    "stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Ensure binary target\n",
    "def ensure_binary_target(y):\n",
    "    unique_values = np.unique(y)\n",
    "    if len(unique_values) > 2:\n",
    "        raise ValueError(\"Target variable contains more than two classes. Please preprocess the data.\")\n",
    "    if unique_values.dtype == bool:\n",
    "        return y.astype(int)\n",
    "    elif set(unique_values) == {0, 1} or set(unique_values) == {1, 0}:\n",
    "        return y\n",
    "    else:\n",
    "        raise ValueError(\"Target variable is not binary. Please preprocess the data.\")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split data into training and testing sets while preserving class distribution\n",
    "def split_data(X, y, N_random_state, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Split the data into training and testing sets while preserving class ratios.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Features.\n",
    "    - y: Target labels.\n",
    "    - test_size: Proportion of the dataset to include in the test split.\n",
    "    - random_state: Random state for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "    - X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=N_random_state, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "# Model selection using cross-validation\n",
    "def model_selection(X_train, y_train):\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(),  # Provides coefficients (coef_)\n",
    "        #\"Ridge Classifier\": LogisticRegression(penalty='l2', solver='liblinear'),  # coef_\n",
    "        #\"Lasso (L1)\": LogisticRegression(penalty='l1', solver='liblinear'),  # coef_\n",
    "        #\"LDA\": LinearDiscriminantAnalysis(),  # Provides coefficients (coef_)\n",
    "        #\"Perceptron\": Perceptron(),  # Provides coefficients (coef_)\n",
    "        #\"SVM (Linear)\": SVC(kernel='linear'),  # Provides coefficients (coef_) when kernel='linear'\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "    best_score = -np.inf\n",
    "    best_name = \"\"\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        cv_score = cross_val_score(model, X_train, y_train, cv=stratified_kfold, scoring='accuracy').mean()\n",
    "        print(f\"Model: {model_name}, CV Score: {cv_score:.4f}\")\n",
    "\n",
    "        if cv_score > best_score:\n",
    "            best_score = cv_score\n",
    "            best_model = model\n",
    "            best_name = model_name\n",
    "\n",
    "    print(f\"Best Model: {best_name} with CV score: {best_score:.4f}\")\n",
    "    return best_model, best_name\n",
    "\n",
    "\n",
    "def feature_selection_with_ChiSquare(X, target, n_features):\n",
    "    from sklearn.feature_selection import SelectKBest, chi2\n",
    "    # Apply Chi-Square Test\n",
    "    X_shifted = X - X.min() + 1e-9\n",
    "    selector = SelectKBest(chi2, k=n_features)  # Select top 2 features\n",
    "    X_selected = selector.fit_transform(X_shifted, target)\n",
    "    \n",
    "    # Get boolean mask of selected features\n",
    "    selected_features_mask = selector.get_support()\n",
    "    \n",
    "    print(\"Selected Features Mask:\", selected_features_mask)\n",
    "    print(\"Scores:\\n\", selector.scores_)\n",
    "    return selected_features_mask\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "\n",
    "def feature_selection_with_rfe(X_train, y_train, n_features, best_model):\n",
    "    \"\"\"\n",
    "    Perform feature selection using RFE, with fallback to univariate selection for models without coefficients.\n",
    "    \"\"\"\n",
    "    if hasattr(best_model, \"coef_\") or hasattr(best_model, \"feature_importances_\"):\n",
    "        # Use RFE for models with coefficients or feature importances\n",
    "        rfe = RFE(estimator=best_model, n_features_to_select=n_features, step=1)\n",
    "        rfe.fit(X_train, y_train)\n",
    "\n",
    "        selected_features = rfe.support_\n",
    "        if np.sum(selected_features) == 0:\n",
    "            print(\"No features selected using RFE. Using all features as fallback.\")\n",
    "            selected_features = np.ones(X_train.shape[1], dtype=bool)\n",
    "\n",
    "    else:\n",
    "        # Fallback to univariate feature selection\n",
    "        print(\"Model lacks coefficients/feature importance; using univariate feature selection.\")\n",
    "        \n",
    "        # Use SelectKBest with F-statistic (or mutual information if preferred)\n",
    "        selector = SelectKBest(score_func=f_classif, k=n_features)\n",
    "        selector.fit(X_train, y_train)\n",
    "\n",
    "        selected_features = selector.get_support()\n",
    "        if np.sum(selected_features) == 0:\n",
    "            print(\"No features selected using univariate method. Using all features as fallback.\")\n",
    "            selected_features = np.ones(X_train.shape[1], dtype=bool)\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_classif\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "def feature_selection_with_rfe_cv(X_train, y_train, best_model, scoring_metric='accuracy'):\n",
    "    \"\"\"\n",
    "    Perform feature selection using RFE or univariate selection, optimizing the number of features automatically\n",
    "    using cross-validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def evaluate_features(model, X, y, num_features):\n",
    "        \"\"\"\n",
    "        Helper function to evaluate the model's performance with the given number of features using cross-validation.\n",
    "        \"\"\"\n",
    "        if hasattr(model, \"coef_\") or hasattr(model, \"feature_importances_\"):\n",
    "            # Perform RFE with the given number of features\n",
    "            rfe = RFE(estimator=model, n_features_to_select=num_features, step=1)\n",
    "            X_selected = rfe.fit_transform(X, y)\n",
    "        else:\n",
    "            # Use univariate feature selection as a fallback\n",
    "            selector = SelectKBest(score_func=f_classif, k=num_features)\n",
    "            X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "        # Evaluate model performance using cross-validation\n",
    "        scores = cross_val_score(model, X_selected, y, cv=stratified_kfold, scoring=scoring_metric)\n",
    "        return scores.mean()\n",
    "\n",
    "    # Iterate over a range of features to find the optimal number of features\n",
    "    best_score = -np.inf\n",
    "    optimal_num_features = 0\n",
    "    for num_features in range(1, X_train.shape[1] + 1):\n",
    "        score = evaluate_features(best_model, X_train, y_train, num_features)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            optimal_num_features = num_features\n",
    "\n",
    "    print(f\"Optimal number of features: {optimal_num_features} with cross-validated score: {best_score:.4f}\")\n",
    "\n",
    "    # Perform final RFE or univariate selection with the optimal number of features\n",
    "    if hasattr(best_model, \"coef_\") or hasattr(best_model, \"feature_importances_\"):\n",
    "        rfe = RFE(estimator=best_model, n_features_to_select=optimal_num_features, step=1)\n",
    "        rfe.fit(X_train, y_train)\n",
    "        selected_features = rfe.support_\n",
    "    else:\n",
    "        selector = SelectKBest(score_func=f_classif, k=optimal_num_features)\n",
    "        selector.fit(X_train, y_train)\n",
    "        selected_features = selector.get_support()\n",
    "\n",
    "    return selected_features, optimal_num_features\n",
    "\n",
    "\n",
    "# Two-step grid search for hyperparameter optimization\n",
    "def tune_model_hyperparameters(model, model_name, X_train, y_train):\n",
    "    refined_grid = {}  # Initialize with a default value to avoid \"unbound variable\" error\n",
    "\n",
    "    if model_name == \"Logistic Regression\":\n",
    "        broad_param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    elif model_name == \"Ridge Classifier\":\n",
    "        broad_param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    elif model_name == \"Lasso (L1)\" or model_name == \"ElasticNet (L1+L2)\":\n",
    "        broad_param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    elif model_name == \"SVM (Linear)\":\n",
    "        broad_param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    elif model_name == \"Random Forest\":\n",
    "        broad_param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30]}\n",
    "    elif model_name == \"Perceptron\":\n",
    "        broad_param_grid = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1]}\n",
    "    elif model_name == \"LDA\":\n",
    "        broad_param_grid = {'shrinkage': [None, 'auto'], 'solver': ['svd', 'lsqr', 'eigen']}\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} does not have a defined parameter grid.\")\n",
    "\n",
    "    # Broad Grid Search\n",
    "    broad_search = GridSearchCV(model, broad_param_grid, cv=stratified_kfold, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    broad_search.fit(X_train, y_train)\n",
    "    best_params_broad = broad_search.best_params_\n",
    "\n",
    "    # Define refined grid based on broad search results\n",
    "    if model_name in [\"Logistic Regression\", \"Lasso (L1)\", \"ElasticNet (L1+L2)\", \"SVM (Linear)\"]:\n",
    "        refined_grid = {'C': np.linspace(best_params_broad['C'] * 0.1, best_params_broad['C'] * 10, 5)}\n",
    "    elif model_name == \"Random Forest\":\n",
    "        refined_grid = {\n",
    "            'n_estimators': [max(10, best_params_broad['n_estimators'] - 50), best_params_broad['n_estimators'], best_params_broad['n_estimators'] + 50],\n",
    "            'max_depth': [None] if not best_params_broad['max_depth'] else [\n",
    "                max(1, best_params_broad['max_depth'] - 5), best_params_broad['max_depth'], best_params_broad['max_depth'] + 5]\n",
    "        }\n",
    "    elif model_name == \"Perceptron\":\n",
    "        refined_grid = {'alpha': np.linspace(best_params_broad['alpha'] * 0.1, best_params_broad['alpha'] * 10, 5)}\n",
    "    elif model_name == \"LDA\":\n",
    "        refined_grid = {'shrinkage': [best_params_broad['shrinkage']], 'solver': [best_params_broad['solver']]}\n",
    "\n",
    "    # Narrow Grid Search\n",
    "    narrow_search = GridSearchCV(model, refined_grid, cv=stratified_kfold, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    narrow_search.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Best Parameters (Broad Search): {best_params_broad}\")\n",
    "    print(f\"Best Parameters (Narrow Search): {narrow_search.best_params_}\")\n",
    "\n",
    "    best_model = narrow_search.best_estimator_\n",
    "    return best_model\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Train and evaluate final model\n",
    "def train_and_evaluate_final_model(X_train, y_train, X_test, y_test, model):\n",
    "    \"\"\"\n",
    "    Train and evaluate the final model. Reports accuracy and AUC.\n",
    "    Parameters:\n",
    "    - X_train: Features for training.\n",
    "    - y_train: Labels for training.\n",
    "    - X_test: Features for testing.\n",
    "    - y_test: Labels for testing.\n",
    "    - model: Machine learning model (must support `fit` and `predict_proba`).\n",
    "\n",
    "    Returns:\n",
    "    - model: Trained model.\n",
    "    - test_accuracy: Accuracy on the test set.\n",
    "    - test_auc: AUC score on the test set.\n",
    "    \"\"\"\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    \n",
    "    # Predict probabilities for AUC computation\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "        test_auc = roc_auc_score(y_test, y_proba)\n",
    "        print(f\"Test Set AUC (Final Model): {test_auc:.4f}\")\n",
    "    else:\n",
    "        print(\"Model does not support probability predictions; skipping AUC computation.\")\n",
    "        test_auc = None\n",
    "\n",
    "    print(f\"Test Set Accuracy (Final Model): {test_accuracy:.4f}\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    return model, test_accuracy, test_auc\n",
    "\n",
    "\n",
    "\n",
    "# Cosine similarity between two models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Extract the weights (coefficients) or feature importances\n",
    "def get_model_vector(model):\n",
    "    if hasattr(model, 'coef_'):  # Linear models with coefficients\n",
    "        return model.coef_.flatten()\n",
    "    elif hasattr(model, 'feature_importances_'):  # Tree-based models\n",
    "        return model.feature_importances_\n",
    "    else:\n",
    "        raise ValueError(f\"Model of type {type(model)} does not have coefficients or feature importances.\")\n",
    "    \n",
    "def calculate_model_similarity(vector1, vector2):\n",
    "    \"\"\"\n",
    "    Calculate the similarity between two models using cosine similarity or feature importances.\n",
    "\n",
    "    Parameters:\n",
    "    - model1: First trained model\n",
    "    - model2: Second trained model\n",
    "\n",
    "    Returns:\n",
    "    - similarity: Cosine similarity score between the two models' coefficients or importances.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure vectors are of the same length\n",
    "        if len(vector1) != len(vector2):\n",
    "            raise ValueError(\"Model vectors have different lengths. Ensure the models were trained on the same features.\")\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        similarity = cosine_similarity([vector1], [vector2])\n",
    "        return similarity[0][0]  # Return the scalar similarity value\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in calculating similarity: {e}\")\n",
    "        return None\n",
    "    \n",
    "def evaluate_model_on_datasets(model, selected_features, datasets, dataset_names, model_name):\n",
    "    \"\"\"\n",
    "    Evaluates the given model on multiple datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The trained model to be evaluated.\n",
    "    - selected_features: The indices of selected features used by the model.\n",
    "    - datasets: List of (X, y) pairs for evaluation.\n",
    "    - dataset_names: List of dataset names corresponding to datasets.\n",
    "    - model_name: Name of the model (used for logging).\n",
    "    \"\"\"\n",
    "    print(f\"\\nEvaluating {model_name} on other datasets:\")\n",
    "    for (X, y), dataset_name in zip(datasets, dataset_names):\n",
    "        X_selected = X[:, selected_features]\n",
    "        y_pred = model.predict(X_selected)\n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        print(f\"\\nAccuracy of {model_name} on {dataset_name}: {accuracy:.4f}\")\n",
    "        \n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_proba = model.predict_proba(X_selected)[:, 1]\n",
    "            auc = roc_auc_score(y, y_proba)\n",
    "            print(f\"{dataset_name} - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "        else:\n",
    "            print(f\"{dataset_name} - Accuracy: {accuracy:.4f}\")\n",
    "            auc = None\n",
    "        \n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y, y_pred))\n",
    "        print(\"Classification Report:\\n\", classification_report(y, y_pred))\n",
    "\n",
    "def delong_roc_test(y_true, auc1, auc2):\n",
    "    se = ((auc1 * (1 - auc1)) + (auc2 * (1 - auc2))) / len(y_true)\n",
    "    z = (auc1 - auc2) / (se ** 0.5)\n",
    "    p_value = norm.sf(abs(z)) * 2  # Two-tailed test\n",
    "    return p_value\n",
    "\n",
    "# Full pipeline\n",
    "def pipeline1(X, y, n_features, N_random_state):\n",
    "    y = ensure_binary_target(y)\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, N_random_state)\n",
    "\n",
    "    best_model, best_name = model_selection(X_train, y_train)\n",
    "\n",
    "    selected_features = feature_selection_with_rfe(X_train, y_train, n_features, best_model)\n",
    "    X_train_selected = X_train[:, selected_features]\n",
    "    X_test_selected = X_test[:, selected_features]\n",
    "\n",
    "    tuned_model = tune_model_hyperparameters(best_model, best_name, X_train_selected, y_train)\n",
    "\n",
    "    final_model, test_accuracy, test_auc = train_and_evaluate_final_model(\n",
    "        X_train_selected, y_train, X_test_selected, y_test, tuned_model\n",
    "    )\n",
    "    return final_model, selected_features, test_accuracy\n",
    "\n",
    "def pipeline2(X, y, N_random_state):\n",
    "    y = ensure_binary_target(y)\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, N_random_state)\n",
    "\n",
    "    best_model, best_name = model_selection(X_train, y_train)\n",
    "\n",
    "    \n",
    "    selected_features, features_number = feature_selection_with_rfe_cv(X_train, y_train, best_model)\n",
    "    X_train_selected = X_train[:, selected_features]\n",
    "    X_test_selected = X_test[:, selected_features]\n",
    "\n",
    "    tuned_model = tune_model_hyperparameters(best_model, best_name, X_train_selected, y_train)\n",
    "\n",
    "    final_model, test_accuracy, test_auc = train_and_evaluate_final_model(\n",
    "        X_train_selected, y_train, X_test_selected, y_test, tuned_model\n",
    "    )\n",
    "    return final_model, selected_features, test_accuracy\n",
    "\n",
    "def compare_models_and_analyze_topography1(X_data_set1, y_data_set1, X_data_set2, y_data_set2, X_data_set3, y_data_set3, X_data_set4, y_data_set4, n_features, N_random_state):\n",
    "    print(\"Training data_set1 model...\")\n",
    "    final_model_data_set1, selected_features_data_set1, test_accuracy_data_set1 = pipeline1(X_data_set1, y_data_set1, n_features, N_random_state)\n",
    "    weight_type1 = get_model_vector(final_model_data_set1)\n",
    "    print(\"\\nTraining data_set2 model...\")\n",
    "    final_model_data_set2, selected_features_data_set2, test_accuracy_data_set2 = pipeline1(X_data_set2, y_data_set2, n_features, N_random_state)\n",
    "    weight_type2 = get_model_vector(final_model_data_set2)\n",
    "    print(\"\\nTraining data_set3 model...\")\n",
    "    final_model_data_set3, selected_features_data_set3, test_accuracy_data_set3 = pipeline1(X_data_set3, y_data_set3, n_features, N_random_state)\n",
    "    weight_type3 = get_model_vector(final_model_data_set3)\n",
    "    print(\"\\nTraining data_set4 model...\")\n",
    "    final_model_data_set4, selected_features_data_set4, test_accuracy_data_set4 = pipeline1(X_data_set4, y_data_set4, n_features, N_random_state)\n",
    "    weight_type4 = get_model_vector(final_model_data_set4)\n",
    "    print(\"\\nEvaluating data_set1 model on other data_sets:\")\n",
    "    \n",
    "    # Datasets and corresponding names\n",
    "    datasets = [(X_data_set1, y_data_set1), (X_data_set2, y_data_set2), \n",
    "                (X_data_set3, y_data_set3), (X_data_set4, y_data_set4)]\n",
    "    dataset_names = [\"data_set1\", \"data_set2\", \"data_set3\", \"data_set4\"]\n",
    "    \n",
    "    # Evaluate models trained on each dataset\n",
    "    evaluate_model_on_datasets(final_model_data_set1, selected_features_data_set1, datasets[1:], dataset_names[1:], \"data_set1 model\")\n",
    "    evaluate_model_on_datasets(final_model_data_set2, selected_features_data_set2, datasets[:1] + datasets[2:], [\"data_set1\"] + dataset_names[2:], \"data_set2 model\")\n",
    "    evaluate_model_on_datasets(final_model_data_set3, selected_features_data_set3, datasets[:2] + datasets[3:], [\"data_set1\", \"data_set2\", \"data_set4\"], \"data_set3 model\")\n",
    "    evaluate_model_on_datasets(final_model_data_set4, selected_features_data_set4, datasets[:3], dataset_names[:3], \"data_set4 model\")\n",
    "    \n",
    "        \n",
    "    return final_model_data_set1, final_model_data_set2, final_model_data_set3, final_model_data_set4,selected_features_data_set1, selected_features_data_set2, selected_features_data_set3, selected_features_data_set4, weight_type1, weight_type2, weight_type3, weight_type4\n",
    "\n",
    "def compare_models_and_analyze_topography2(X_data_set1, y_data_set1, X_data_set2, y_data_set2, N_random_state):\n",
    "    print(\"Training data_set1 model...\")\n",
    "    final_model_data_set1, selected_features_data_set1, test_accuracy_data_set1 = pipeline2(X_data_set1, y_data_set1, N_random_state)\n",
    "    # X_data_set1_selected = X_data_set1[:, selected_features_data_set1]\n",
    "    # y_pred = final_model_data_set1.predict(X_data_set1_selected)\n",
    "    # print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set1, y_pred))\n",
    "    # print(\"Classification Report:\\n\", classification_report(y_data_set1, y_pred))\n",
    "    \n",
    "    print(\"\\nTraining data_set2 model...\")\n",
    "    final_model_data_set2, selected_features_data_set2, test_accuracy_data_set2 = pipeline2(X_data_set2, y_data_set2, N_random_state)\n",
    "    # X_data_set2_selected = X_data_set2[:, selected_features_data_set2]\n",
    "    # y_pred2 = final_model_data_set2.predict(X_data_set2_selected)\n",
    "    # print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set2, y_pred2))\n",
    "    # print(\"Classification Report:\\n\", classification_report(y_data_set2, y_pred2))\n",
    "    \n",
    "\n",
    "    print(\"\\nEvaluating data_set1 model on data_set2 dataset:\")\n",
    "    X_data_set2_selected = X_data_set2[:, selected_features_data_set1]\n",
    "    y_pred_data_set2 = final_model_data_set1.predict(X_data_set2_selected)\n",
    "    accuracy = accuracy_score(y_data_set2, y_pred_data_set2)\n",
    "    print(f\"Accuracy of data_set1 model on data_set2 data: {accuracy:.4f}\")\n",
    "    # Check if the model supports probability predictions for AUC computation\n",
    "    if hasattr(final_model_data_set1, \"predict_proba\"):\n",
    "        y_proba_data_set2 = final_model_data_set1.predict_proba(X_data_set2_selected)[:, 1]  # Probabilities for the positive class\n",
    "        auc = roc_auc_score(y_data_set2, y_proba_data_set2)\n",
    "        print(f\"Dataset 2 - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "    else:\n",
    "        print(f\"Dataset 2 - Accuracy: {accuracy:.4f}\")\n",
    "        auc = None  # AUC not computed due to lack of probability support\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_data_set2, y_pred_data_set2))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_data_set2, y_pred_data_set2))\n",
    "\n",
    "    print(\"\\nCalculating cosine similarity between data_set1 and data_set2 model weights:\")\n",
    "    try:\n",
    "        similarity = calculate_model_similarity(final_model_data_set1, final_model_data_set2)\n",
    "        print(f\"Cosine similarity between data_set1 and data_set2 model weights: {similarity:.4f}\")\n",
    "    except ValueError as e:\n",
    "        similarity = \"N/A (Model type not compatible for cosine similarity)\"\n",
    "        print(f\"Cosine similarity between data_set1 and data_set2 model weights: {similarity}\")\n",
    "    return similarity, test_accuracy_data_set1"
   ],
   "id": "38057e503ee5f37b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T21:52:10.572946Z",
     "start_time": "2025-02-12T21:52:10.570854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define user inputs\n",
    "user_dir = \"/Users/xiaoqianxiao\"\n",
    "project_name = \"UKB\"\n",
    "session_ID = 2  # Specify session"
   ],
   "id": "b740d21222085251",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T21:53:37.624060Z",
     "start_time": "2025-02-12T21:52:17.445363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_set = \"ah\"  # Dataset identifier\n",
    "X_ah, df_ah = process_fMRI_data(data_set, user_dir, project_name, session_ID, dic_cortical_roi, subcortical_index)\n",
    "y_ah = df_ah[\"active_history\"]\n",
    "\n",
    "data_set = \"ih\"  # Dataset identifier\n",
    "X_ih, df_ih = process_fMRI_data(data_set, user_dir, project_name, session_ID, dic_cortical_roi, subcortical_index)\n",
    "y_ih = df_ih[\"inactive_history\"]\n",
    "\n",
    "data_set = \"a_noh\"  # Dataset identifier\n",
    "X_a_noh, df_a_noh = process_fMRI_data(data_set, user_dir, project_name, session_ID, dic_cortical_roi, subcortical_index)\n",
    "y_a_noh = df_a_noh[\"active_no_history\"]"
   ],
   "id": "b1ebe252c24112b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files for subject 1529291, session 2.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T21:54:13.423243Z",
     "start_time": "2025-02-12T21:54:13.420240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from itertools import compress\n",
    "filtered_list_ah = list(compress(X_ah, y_ah))\n",
    "my_array = np.array(filtered_list_ah)\n",
    "data = my_array"
   ],
   "id": "d18e7de27297ae8b",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T22:07:56.010562Z",
     "start_time": "2025-02-12T22:07:24.033259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "selected_features = feature_selection_with_rfe_cv(X_ah, y_ah, best_model, scoring_metric='roc_auc')"
   ],
   "id": "6f05f4cbdcf436e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 4 with cross-validated score: 0.6139\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T22:17:40.137727Z",
     "start_time": "2025-02-12T22:17:40.134925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pipeline_FeatureSelection(X, y, n_features, N_random_state):\n",
    "    y = ensure_binary_target(y)\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, N_random_state)\n",
    "\n",
    "    best_model, best_name = model_selection(X_train, y_train)\n",
    "\n",
    "    selected_features = feature_selection_with_rfe(X_train, y_train, n_features, best_model)\n",
    "    \n",
    "    return selected_features"
   ],
   "id": "e9a12dcb7bb90e83",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T22:19:08.708260Z",
     "start_time": "2025-02-12T22:19:08.661945Z"
    }
   },
   "cell_type": "code",
   "source": "selected_features = pipeline_FeatureSelection(X_ah, y_ah, 30, 422)",
   "id": "54a217c389d16c24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression, CV Score: 0.5310\n",
      "Best Model: Logistic Regression with CV score: 0.5310\n",
      "Model lacks coefficients/feature importance; using univariate feature selection.\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "12d3338477797748"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
